{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Nanodegree\n",
    "\n",
    "## Project: Image Captioning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will train your CNN-RNN model.  \n",
    "\n",
    "You are welcome and encouraged to try out many different architectures and hyperparameters when searching for a good model.\n",
    "\n",
    "This does have the potential to make the project quite messy!  Before submitting your project, make sure that you clean up:\n",
    "- the code you write in this notebook.  The notebook should describe how to train a single CNN-RNN architecture, corresponding to your final choice of hyperparameters.  You should structure the notebook so that the reviewer can replicate your results by running the code in this notebook.  \n",
    "- the output of the code cell in **Step 2**.  The output should show the output obtained when training the model from scratch.\n",
    "\n",
    "This notebook **will be graded**.  \n",
    "\n",
    "Feel free to use the links below to navigate the notebook:\n",
    "- [Step 1](#step1): Training Setup\n",
    "- [Step 2](#step2): Train your Model\n",
    "- [Step 3](#step3): (Optional) Validate your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Training Setup\n",
    "\n",
    "In this step of the notebook, you will customize the training of your CNN-RNN model by specifying hyperparameters and setting other options that are important to the training procedure.  The values you set now will be used when training your model in **Step 2** below.\n",
    "\n",
    "You should only amend blocks of code that are preceded by a `TODO` statement.  **Any code blocks that are not preceded by a `TODO` statement should not be modified**.\n",
    "\n",
    "### Task #1\n",
    "\n",
    "Begin by setting the following variables:\n",
    "- `batch_size` - the batch size of each training batch.  It is the number of image-caption pairs used to amend the model weights in each training step. \n",
    "- `vocab_threshold` - the minimum word count threshold.  Note that a larger threshold will result in a smaller vocabulary, whereas a smaller threshold will include rarer words and result in a larger vocabulary.  \n",
    "- `vocab_from_file` - a Boolean that decides whether to load the vocabulary from file. \n",
    "- `embed_size` - the dimensionality of the image and word embeddings.  \n",
    "- `hidden_size` - the number of features in the hidden state of the RNN decoder.  \n",
    "- `num_epochs` - the number of epochs to train the model.  We recommend that you set `num_epochs=3`, but feel free to increase or decrease this number as you wish.  [This paper](https://arxiv.org/pdf/1502.03044.pdf) trained a captioning model on a single state-of-the-art GPU for 3 days, but you'll soon see that you can get reasonable results in a matter of a few hours!  (_But of course, if you want your model to compete with current research, you will have to train for much longer._)\n",
    "- `save_every` - determines how often to save the model weights.  We recommend that you set `save_every=1`, to save the model weights after each epoch.  This way, after the `i`th epoch, the encoder and decoder weights will be saved in the `models/` folder as `encoder-i.pkl` and `decoder-i.pkl`, respectively.\n",
    "- `print_every` - determines how often to print the batch loss to the Jupyter notebook while training.  Note that you **will not** observe a monotonic decrease in the loss function while training - this is perfectly fine and completely expected!  You are encouraged to keep this at its default value of `100` to avoid clogging the notebook, but feel free to change it.\n",
    "- `log_file` - the name of the text file containing - for every step - how the loss and perplexity evolved during training.\n",
    "\n",
    "If you're not sure where to begin to set some of the values above, you can peruse [this paper](https://arxiv.org/pdf/1502.03044.pdf) and [this paper](https://arxiv.org/pdf/1411.4555.pdf) for useful guidance!  **To avoid spending too long on this notebook**, you are encouraged to consult these suggested research papers to obtain a strong initial guess for which hyperparameters are likely to work best.  Then, train a single model, and proceed to the next notebook (**3_Inference.ipynb**).  If you are unhappy with your performance, you can return to this notebook to tweak the hyperparameters (and/or the architecture in **model.py**) and re-train your model.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "**Question:** Describe your CNN-RNN architecture in detail.  With this architecture in mind, how did you select the values of the variables in Task 1?  If you consulted a research paper detailing a successful implementation of an image captioning model, please provide the reference.\n",
    "\n",
    "**Answer:** \n",
    "\n",
    "\n",
    "### (Optional) Task #2\n",
    "\n",
    "Note that we have provided a recommended image transform `transform_train` for pre-processing the training images, but you are welcome (and encouraged!) to modify it as you wish.  When modifying this transform, keep in mind that:\n",
    "- the images in the dataset have varying heights and widths, and \n",
    "- if using a pre-trained model, you must perform the corresponding appropriate normalization.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "**Question:** How did you select the transform in `transform_train`?  If you left the transform at its provided value, why do you think that it is a good choice for your CNN architecture?\n",
    "\n",
    "**Answer:** \n",
    "\n",
    "### Task #3\n",
    "\n",
    "Next, you will specify a Python list containing the learnable parameters of the model.  For instance, if you decide to make all weights in the decoder trainable, but only want to train the weights in the embedding layer of the encoder, then you should set `params` to something like:\n",
    "```\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "```\n",
    "\n",
    "### Question 3\n",
    "\n",
    "**Question:** How did you select the trainable parameters of your architecture?  Why do you think this is a good choice?\n",
    "\n",
    "**Answer:** \n",
    "\n",
    "### Task #4\n",
    "\n",
    "Finally, you will select an [optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Optimizer).\n",
    "\n",
    "### Question 4\n",
    "\n",
    "**Question:** How did you select the optimizer used to train your model?\n",
    "\n",
    "**Answer:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/414113 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 373/414113 [00:00<01:51, 3724.75it/s]\u001b[A\n",
      "  0%|          | 740/414113 [00:00<01:51, 3705.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=1.07s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  0%|          | 1169/414113 [00:00<01:46, 3862.65it/s]\u001b[A\n",
      "  0%|          | 1576/414113 [00:00<01:45, 3922.13it/s]\u001b[A\n",
      "  0%|          | 1996/414113 [00:00<01:43, 4000.15it/s]\u001b[A\n",
      "  1%|          | 2422/414113 [00:00<01:41, 4073.08it/s]\u001b[A\n",
      "  1%|          | 2848/414113 [00:00<01:39, 4126.14it/s]\u001b[A\n",
      "  1%|          | 3260/414113 [00:00<01:39, 4122.63it/s]\u001b[A\n",
      "  1%|          | 3690/414113 [00:00<01:38, 4172.37it/s]\u001b[A\n",
      "  1%|          | 4105/414113 [00:01<01:38, 4163.08it/s]\u001b[A\n",
      "  1%|          | 4536/414113 [00:01<01:37, 4203.80it/s]\u001b[A\n",
      "  1%|          | 4970/414113 [00:01<01:36, 4241.41it/s]\u001b[A\n",
      "  1%|▏         | 5407/414113 [00:01<01:35, 4279.00it/s]\u001b[A\n",
      "  1%|▏         | 5833/414113 [00:01<01:35, 4271.73it/s]\u001b[A\n",
      "  2%|▏         | 6258/414113 [00:01<01:35, 4264.35it/s]\u001b[A\n",
      "  2%|▏         | 6686/414113 [00:01<01:35, 4268.28it/s]\u001b[A\n",
      "  2%|▏         | 7112/414113 [00:01<01:39, 4089.94it/s]\u001b[A\n",
      "  2%|▏         | 7522/414113 [00:01<01:39, 4091.75it/s]\u001b[A\n",
      "  2%|▏         | 7945/414113 [00:01<01:38, 4130.54it/s]\u001b[A\n",
      "  2%|▏         | 8384/414113 [00:02<01:36, 4202.41it/s]\u001b[A\n",
      "  2%|▏         | 8815/414113 [00:02<01:35, 4231.66it/s]\u001b[A\n",
      "  2%|▏         | 9240/414113 [00:02<01:35, 4234.86it/s]\u001b[A\n",
      "  2%|▏         | 9670/414113 [00:02<01:35, 4251.95it/s]\u001b[A\n",
      "  2%|▏         | 10096/414113 [00:02<01:35, 4250.21it/s]\u001b[A\n",
      "  3%|▎         | 10527/414113 [00:02<01:34, 4266.11it/s]\u001b[A\n",
      "  3%|▎         | 10956/414113 [00:02<01:34, 4273.12it/s]\u001b[A\n",
      "  3%|▎         | 11384/414113 [00:02<01:34, 4264.51it/s]\u001b[A\n",
      "  3%|▎         | 11811/414113 [00:02<01:34, 4252.14it/s]\u001b[A\n",
      "  3%|▎         | 12237/414113 [00:02<01:34, 4242.70it/s]\u001b[A\n",
      "  3%|▎         | 12662/414113 [00:03<01:34, 4226.90it/s]\u001b[A\n",
      "  3%|▎         | 13088/414113 [00:03<01:34, 4233.91it/s]\u001b[A\n",
      "  3%|▎         | 13520/414113 [00:03<01:34, 4258.65it/s]\u001b[A\n",
      "  3%|▎         | 13952/414113 [00:03<01:33, 4274.26it/s]\u001b[A\n",
      "  3%|▎         | 14394/414113 [00:03<01:32, 4314.44it/s]\u001b[A\n",
      "  4%|▎         | 14826/414113 [00:03<01:33, 4273.67it/s]\u001b[A\n",
      "  4%|▎         | 15255/414113 [00:03<01:33, 4277.27it/s]\u001b[A\n",
      "  4%|▍         | 15683/414113 [00:03<01:34, 4228.69it/s]\u001b[A\n",
      "  4%|▍         | 16110/414113 [00:03<01:33, 4239.65it/s]\u001b[A\n",
      "  4%|▍         | 16538/414113 [00:03<01:33, 4251.16it/s]\u001b[A\n",
      "  4%|▍         | 16970/414113 [00:04<01:32, 4271.42it/s]\u001b[A\n",
      "  4%|▍         | 17398/414113 [00:04<01:35, 4138.78it/s]\u001b[A\n",
      "  4%|▍         | 17826/414113 [00:04<01:34, 4179.39it/s]\u001b[A\n",
      "  4%|▍         | 18250/414113 [00:04<01:34, 4195.98it/s]\u001b[A\n",
      "  5%|▍         | 18685/414113 [00:04<01:33, 4239.10it/s]\u001b[A\n",
      "  5%|▍         | 19114/414113 [00:04<01:32, 4252.93it/s]\u001b[A\n",
      "  5%|▍         | 19560/414113 [00:04<01:31, 4310.46it/s]\u001b[A\n",
      "  5%|▍         | 19992/414113 [00:04<01:31, 4294.11it/s]\u001b[A\n",
      "  5%|▍         | 20425/414113 [00:04<01:31, 4304.80it/s]\u001b[A\n",
      "  5%|▌         | 20861/414113 [00:04<01:31, 4319.10it/s]\u001b[A\n",
      "  5%|▌         | 21294/414113 [00:05<01:31, 4294.72it/s]\u001b[A\n",
      "  5%|▌         | 21737/414113 [00:05<01:30, 4334.25it/s]\u001b[A\n",
      "  5%|▌         | 22171/414113 [00:05<01:30, 4329.11it/s]\u001b[A\n",
      "  5%|▌         | 22614/414113 [00:05<01:29, 4358.71it/s]\u001b[A\n",
      "  6%|▌         | 23063/414113 [00:05<01:28, 4395.08it/s]\u001b[A\n",
      "  6%|▌         | 23503/414113 [00:05<01:29, 4370.27it/s]\u001b[A\n",
      "  6%|▌         | 23941/414113 [00:05<01:30, 4326.41it/s]\u001b[A\n",
      "  6%|▌         | 24374/414113 [00:05<01:30, 4320.54it/s]\u001b[A\n",
      "  6%|▌         | 24811/414113 [00:05<01:29, 4333.57it/s]\u001b[A\n",
      "  6%|▌         | 25245/414113 [00:05<01:30, 4303.85it/s]\u001b[A\n",
      "  6%|▌         | 25679/414113 [00:06<01:30, 4313.81it/s]\u001b[A\n",
      "  6%|▋         | 26112/414113 [00:06<01:29, 4318.51it/s]\u001b[A\n",
      "  6%|▋         | 26544/414113 [00:06<01:29, 4314.78it/s]\u001b[A\n",
      "  7%|▋         | 26976/414113 [00:06<01:29, 4309.14it/s]\u001b[A\n",
      "  7%|▋         | 27408/414113 [00:06<01:29, 4309.94it/s]\u001b[A\n",
      "  7%|▋         | 27840/414113 [00:06<01:30, 4282.92it/s]\u001b[A\n",
      "  7%|▋         | 28273/414113 [00:06<01:29, 4293.99it/s]\u001b[A\n",
      "  7%|▋         | 28712/414113 [00:06<01:29, 4321.21it/s]\u001b[A\n",
      "  7%|▋         | 29147/414113 [00:06<01:28, 4327.51it/s]\u001b[A\n",
      "  7%|▋         | 29580/414113 [00:06<01:28, 4325.22it/s]\u001b[A\n",
      "  7%|▋         | 30022/414113 [00:07<01:28, 4351.56it/s]\u001b[A\n",
      "  7%|▋         | 30458/414113 [00:07<01:28, 4337.50it/s]\u001b[A\n",
      "  7%|▋         | 30901/414113 [00:07<01:27, 4361.96it/s]\u001b[A\n",
      "  8%|▊         | 31338/414113 [00:07<01:28, 4346.84it/s]\u001b[A\n",
      "  8%|▊         | 31774/414113 [00:07<01:27, 4349.30it/s]\u001b[A\n",
      "  8%|▊         | 32209/414113 [00:07<01:27, 4344.00it/s]\u001b[A\n",
      "  8%|▊         | 32648/414113 [00:07<01:27, 4355.08it/s]\u001b[A\n",
      "  8%|▊         | 33084/414113 [00:07<01:28, 4308.78it/s]\u001b[A\n",
      "  8%|▊         | 33516/414113 [00:07<01:28, 4307.18it/s]\u001b[A\n",
      "  8%|▊         | 33949/414113 [00:07<01:28, 4313.78it/s]\u001b[A\n",
      "  8%|▊         | 34386/414113 [00:08<01:27, 4328.62it/s]\u001b[A\n",
      "  8%|▊         | 34819/414113 [00:08<01:28, 4288.35it/s]\u001b[A\n",
      "  9%|▊         | 35249/414113 [00:08<01:28, 4289.61it/s]\u001b[A\n",
      "  9%|▊         | 35679/414113 [00:08<01:28, 4263.26it/s]\u001b[A\n",
      "  9%|▊         | 36106/414113 [00:08<01:28, 4249.04it/s]\u001b[A\n",
      "  9%|▉         | 36544/414113 [00:08<01:28, 4286.90it/s]\u001b[A\n",
      "  9%|▉         | 36985/414113 [00:08<01:27, 4322.94it/s]\u001b[A\n",
      "  9%|▉         | 37418/414113 [00:08<01:27, 4322.53it/s]\u001b[A\n",
      "  9%|▉         | 37853/414113 [00:08<01:26, 4330.70it/s]\u001b[A\n",
      "  9%|▉         | 38287/414113 [00:08<01:27, 4294.66it/s]\u001b[A\n",
      "  9%|▉         | 38717/414113 [00:09<01:27, 4283.94it/s]\u001b[A\n",
      "  9%|▉         | 39148/414113 [00:09<01:27, 4289.15it/s]\u001b[A\n",
      " 10%|▉         | 39577/414113 [00:09<01:27, 4278.87it/s]\u001b[A\n",
      " 10%|▉         | 40011/414113 [00:09<01:27, 4295.12it/s]\u001b[A\n",
      " 10%|▉         | 40441/414113 [00:09<01:28, 4241.24it/s]\u001b[A\n",
      " 10%|▉         | 40878/414113 [00:09<01:27, 4277.40it/s]\u001b[A\n",
      " 10%|▉         | 41316/414113 [00:09<01:26, 4304.98it/s]\u001b[A\n",
      " 10%|█         | 41747/414113 [00:09<01:26, 4287.88it/s]\u001b[A\n",
      " 10%|█         | 42176/414113 [00:09<01:27, 4267.08it/s]\u001b[A\n",
      " 10%|█         | 42619/414113 [00:09<01:26, 4312.85it/s]\u001b[A\n",
      " 10%|█         | 43052/414113 [00:10<01:25, 4315.58it/s]\u001b[A\n",
      " 11%|█         | 43495/414113 [00:10<01:25, 4348.81it/s]\u001b[A\n",
      " 11%|█         | 43933/414113 [00:10<01:24, 4356.84it/s]\u001b[A\n",
      " 11%|█         | 44372/414113 [00:10<01:24, 4364.66it/s]\u001b[A\n",
      " 11%|█         | 44809/414113 [00:10<01:24, 4361.78it/s]\u001b[A\n",
      " 11%|█         | 45246/414113 [00:10<01:24, 4345.01it/s]\u001b[A\n",
      " 11%|█         | 45681/414113 [00:10<01:24, 4338.90it/s]\u001b[A\n",
      " 11%|█         | 46115/414113 [00:10<01:24, 4334.79it/s]\u001b[A\n",
      " 11%|█         | 46549/414113 [00:10<01:25, 4289.47it/s]\u001b[A\n",
      " 11%|█▏        | 46979/414113 [00:10<01:26, 4267.58it/s]\u001b[A\n",
      " 11%|█▏        | 47406/414113 [00:11<01:26, 4263.28it/s]\u001b[A\n",
      " 12%|█▏        | 47841/414113 [00:11<01:25, 4286.96it/s]\u001b[A\n",
      " 12%|█▏        | 48275/414113 [00:11<01:25, 4301.19it/s]\u001b[A\n",
      " 12%|█▏        | 48706/414113 [00:11<01:25, 4297.49it/s]\u001b[A\n",
      " 12%|█▏        | 49139/414113 [00:11<01:24, 4306.22it/s]\u001b[A\n",
      " 12%|█▏        | 49570/414113 [00:11<01:25, 4275.18it/s]\u001b[A\n",
      " 12%|█▏        | 50008/414113 [00:11<01:24, 4305.82it/s]\u001b[A\n",
      " 12%|█▏        | 50449/414113 [00:11<01:23, 4335.78it/s]\u001b[A\n",
      " 12%|█▏        | 50883/414113 [00:11<01:24, 4274.96it/s]\u001b[A\n",
      " 12%|█▏        | 51328/414113 [00:12<01:23, 4325.12it/s]\u001b[A\n",
      " 13%|█▎        | 51769/414113 [00:12<01:23, 4349.20it/s]\u001b[A\n",
      " 13%|█▎        | 52208/414113 [00:12<01:23, 4359.42it/s]\u001b[A\n",
      " 13%|█▎        | 52645/414113 [00:12<01:23, 4347.54it/s]\u001b[A\n",
      " 13%|█▎        | 53084/414113 [00:12<01:22, 4357.32it/s]\u001b[A\n",
      " 13%|█▎        | 53520/414113 [00:12<01:22, 4356.61it/s]\u001b[A\n",
      " 13%|█▎        | 53963/414113 [00:12<01:22, 4375.34it/s]\u001b[A\n",
      " 13%|█▎        | 54401/414113 [00:12<01:22, 4368.34it/s]\u001b[A\n",
      " 13%|█▎        | 54838/414113 [00:12<01:22, 4356.77it/s]\u001b[A\n",
      " 13%|█▎        | 55286/414113 [00:12<01:21, 4392.22it/s]\u001b[A\n",
      " 13%|█▎        | 55726/414113 [00:13<01:21, 4381.35it/s]\u001b[A\n",
      " 14%|█▎        | 56172/414113 [00:13<01:21, 4404.02it/s]\u001b[A\n",
      " 14%|█▎        | 56618/414113 [00:13<01:20, 4418.42it/s]\u001b[A\n",
      " 14%|█▍        | 57060/414113 [00:13<01:21, 4398.31it/s]\u001b[A\n",
      " 14%|█▍        | 57500/414113 [00:13<01:21, 4396.68it/s]\u001b[A\n",
      " 14%|█▍        | 57940/414113 [00:13<01:21, 4395.49it/s]\u001b[A\n",
      " 14%|█▍        | 58385/414113 [00:13<01:20, 4411.70it/s]\u001b[A\n",
      " 14%|█▍        | 58827/414113 [00:13<01:21, 4370.35it/s]\u001b[A\n",
      " 14%|█▍        | 59265/414113 [00:13<01:21, 4367.69it/s]\u001b[A\n",
      " 14%|█▍        | 59703/414113 [00:13<01:21, 4369.63it/s]\u001b[A\n",
      " 15%|█▍        | 60149/414113 [00:14<01:20, 4393.96it/s]\u001b[A\n",
      " 15%|█▍        | 60589/414113 [00:14<01:20, 4394.00it/s]\u001b[A\n",
      " 15%|█▍        | 61035/414113 [00:14<01:20, 4411.57it/s]\u001b[A\n",
      " 15%|█▍        | 61480/414113 [00:14<01:19, 4419.67it/s]\u001b[A\n",
      " 15%|█▍        | 61923/414113 [00:14<01:19, 4414.92it/s]\u001b[A\n",
      " 15%|█▌        | 62365/414113 [00:14<01:19, 4412.51it/s]\u001b[A\n",
      " 15%|█▌        | 62807/414113 [00:14<01:20, 4366.56it/s]\u001b[A\n",
      " 15%|█▌        | 63244/414113 [00:14<01:20, 4358.16it/s]\u001b[A\n",
      " 15%|█▌        | 63682/414113 [00:14<01:20, 4361.29it/s]\u001b[A\n",
      " 15%|█▌        | 64136/414113 [00:14<01:19, 4412.10it/s]\u001b[A\n",
      " 16%|█▌        | 64583/414113 [00:15<01:18, 4429.02it/s]\u001b[A\n",
      " 16%|█▌        | 65027/414113 [00:15<01:19, 4384.22it/s]\u001b[A\n",
      " 16%|█▌        | 65466/414113 [00:15<01:20, 4339.01it/s]\u001b[A\n",
      " 16%|█▌        | 65901/414113 [00:15<01:20, 4314.55it/s]\u001b[A\n",
      " 16%|█▌        | 66339/414113 [00:15<01:20, 4333.87it/s]\u001b[A\n",
      " 16%|█▌        | 66781/414113 [00:15<01:19, 4357.99it/s]\u001b[A\n",
      " 16%|█▌        | 67222/414113 [00:15<01:19, 4370.64it/s]\u001b[A\n",
      " 16%|█▋        | 67660/414113 [00:15<01:19, 4332.69it/s]\u001b[A\n",
      " 16%|█▋        | 68094/414113 [00:15<01:19, 4332.23it/s]\u001b[A\n",
      " 17%|█▋        | 68528/414113 [00:15<01:20, 4295.92it/s]\u001b[A\n",
      " 17%|█▋        | 68970/414113 [00:16<01:19, 4330.39it/s]\u001b[A\n",
      " 17%|█▋        | 69404/414113 [00:16<01:19, 4329.30it/s]\u001b[A\n",
      " 17%|█▋        | 69845/414113 [00:16<01:19, 4350.22it/s]\u001b[A\n",
      " 17%|█▋        | 70283/414113 [00:16<01:18, 4357.53it/s]\u001b[A\n",
      " 17%|█▋        | 70719/414113 [00:16<01:19, 4345.85it/s]\u001b[A\n",
      " 17%|█▋        | 71155/414113 [00:16<01:18, 4345.55it/s]\u001b[A\n",
      " 17%|█▋        | 71590/414113 [00:16<01:19, 4332.03it/s]\u001b[A\n",
      " 17%|█▋        | 72024/414113 [00:16<01:18, 4333.68it/s]\u001b[A\n",
      " 17%|█▋        | 72458/414113 [00:16<01:19, 4318.53it/s]\u001b[A\n",
      " 18%|█▊        | 72890/414113 [00:16<01:19, 4302.48it/s]\u001b[A\n",
      " 18%|█▊        | 73331/414113 [00:17<01:18, 4332.57it/s]\u001b[A\n",
      " 18%|█▊        | 73765/414113 [00:17<01:18, 4309.44it/s]\u001b[A\n",
      " 18%|█▊        | 74197/414113 [00:17<02:07, 2673.81it/s]\u001b[A\n",
      " 18%|█▊        | 74638/414113 [00:17<01:51, 3031.45it/s]\u001b[A\n",
      " 18%|█▊        | 75048/414113 [00:17<01:43, 3286.56it/s]\u001b[A\n",
      " 18%|█▊        | 75472/414113 [00:17<01:36, 3523.35it/s]\u001b[A\n",
      " 18%|█▊        | 75902/414113 [00:17<01:30, 3723.38it/s]\u001b[A\n",
      " 18%|█▊        | 76323/414113 [00:17<01:27, 3855.68it/s]\u001b[A\n",
      " 19%|█▊        | 76766/414113 [00:18<01:24, 4009.80it/s]\u001b[A\n",
      " 19%|█▊        | 77194/414113 [00:18<01:22, 4085.83it/s]\u001b[A\n",
      " 19%|█▊        | 77630/414113 [00:18<01:20, 4163.08it/s]\u001b[A\n",
      " 19%|█▉        | 78070/414113 [00:18<01:19, 4231.24it/s]\u001b[A\n",
      " 19%|█▉        | 78514/414113 [00:18<01:18, 4290.35it/s]\u001b[A\n",
      " 19%|█▉        | 78955/414113 [00:18<01:17, 4324.31it/s]\u001b[A\n",
      " 19%|█▉        | 79392/414113 [00:18<01:17, 4336.51it/s]\u001b[A\n",
      " 19%|█▉        | 79829/414113 [00:18<01:17, 4330.49it/s]\u001b[A\n",
      " 19%|█▉        | 80265/414113 [00:18<01:16, 4336.60it/s]\u001b[A\n",
      " 19%|█▉        | 80701/414113 [00:18<01:16, 4340.66it/s]\u001b[A\n",
      " 20%|█▉        | 81136/414113 [00:19<01:16, 4328.22it/s]\u001b[A\n",
      " 20%|█▉        | 81570/414113 [00:19<01:17, 4316.53it/s]\u001b[A\n",
      " 20%|█▉        | 82013/414113 [00:19<01:16, 4347.84it/s]\u001b[A\n",
      " 20%|█▉        | 82449/414113 [00:19<01:17, 4291.23it/s]\u001b[A\n",
      " 20%|██        | 82879/414113 [00:19<01:17, 4283.11it/s]\u001b[A\n",
      " 20%|██        | 83330/414113 [00:19<01:16, 4347.95it/s]\u001b[A\n",
      " 20%|██        | 83770/414113 [00:19<01:15, 4360.26it/s]\u001b[A\n",
      " 20%|██        | 84207/414113 [00:19<01:15, 4348.09it/s]\u001b[A\n",
      " 20%|██        | 84643/414113 [00:19<01:15, 4340.05it/s]\u001b[A\n",
      " 21%|██        | 85087/414113 [00:19<01:15, 4367.71it/s]\u001b[A\n",
      " 21%|██        | 85524/414113 [00:20<01:15, 4359.89it/s]\u001b[A\n",
      " 21%|██        | 85961/414113 [00:20<01:15, 4355.05it/s]\u001b[A\n",
      " 21%|██        | 86397/414113 [00:20<01:15, 4356.32it/s]\u001b[A\n",
      " 21%|██        | 86833/414113 [00:20<01:15, 4319.35it/s]\u001b[A\n",
      " 21%|██        | 87268/414113 [00:20<01:15, 4324.35it/s]\u001b[A\n",
      " 21%|██        | 87707/414113 [00:20<01:15, 4343.54it/s]\u001b[A\n",
      " 21%|██▏       | 88150/414113 [00:20<01:14, 4366.86it/s]\u001b[A\n",
      " 21%|██▏       | 88587/414113 [00:20<01:15, 4289.76it/s]\u001b[A\n",
      " 21%|██▏       | 89024/414113 [00:20<01:15, 4312.53it/s]\u001b[A\n",
      " 22%|██▏       | 89462/414113 [00:20<01:14, 4330.20it/s]\u001b[A\n",
      " 22%|██▏       | 89900/414113 [00:21<01:14, 4344.93it/s]\u001b[A\n",
      " 22%|██▏       | 90335/414113 [00:21<01:14, 4330.80it/s]\u001b[A\n",
      " 22%|██▏       | 90769/414113 [00:21<01:14, 4320.68it/s]\u001b[A\n",
      " 22%|██▏       | 91202/414113 [00:21<01:15, 4301.60it/s]\u001b[A\n",
      " 22%|██▏       | 91639/414113 [00:21<01:14, 4319.90it/s]\u001b[A\n",
      " 22%|██▏       | 92081/414113 [00:21<01:14, 4349.33it/s]\u001b[A\n",
      " 22%|██▏       | 92517/414113 [00:21<01:14, 4324.38it/s]\u001b[A\n",
      " 22%|██▏       | 92952/414113 [00:21<01:14, 4330.19it/s]\u001b[A\n",
      " 23%|██▎       | 93393/414113 [00:21<01:13, 4352.95it/s]\u001b[A\n",
      " 23%|██▎       | 93829/414113 [00:21<01:13, 4339.82it/s]\u001b[A\n",
      " 23%|██▎       | 94274/414113 [00:22<01:13, 4371.91it/s]\u001b[A\n",
      " 23%|██▎       | 94712/414113 [00:22<01:13, 4366.23it/s]\u001b[A\n",
      " 23%|██▎       | 95149/414113 [00:22<01:13, 4359.36it/s]\u001b[A\n",
      " 23%|██▎       | 95594/414113 [00:22<01:12, 4384.31it/s]\u001b[A\n",
      " 23%|██▎       | 96033/414113 [00:22<01:13, 4327.49it/s]\u001b[A\n",
      " 23%|██▎       | 96473/414113 [00:22<01:13, 4346.99it/s]\u001b[A\n",
      " 23%|██▎       | 96908/414113 [00:22<01:12, 4346.20it/s]\u001b[A\n",
      " 24%|██▎       | 97343/414113 [00:22<01:13, 4327.50it/s]\u001b[A\n",
      " 24%|██▎       | 97788/414113 [00:22<01:12, 4361.84it/s]\u001b[A\n",
      " 24%|██▎       | 98226/414113 [00:22<01:12, 4366.89it/s]\u001b[A\n",
      " 24%|██▍       | 98663/414113 [00:23<01:12, 4344.49it/s]\u001b[A\n",
      " 24%|██▍       | 99098/414113 [00:23<01:13, 4293.87it/s]\u001b[A\n",
      " 24%|██▍       | 99535/414113 [00:23<01:12, 4314.22it/s]\u001b[A\n",
      " 24%|██▍       | 99972/414113 [00:23<01:12, 4328.02it/s]\u001b[A\n",
      " 24%|██▍       | 100405/414113 [00:23<01:12, 4304.28it/s]\u001b[A\n",
      " 24%|██▍       | 100844/414113 [00:23<01:12, 4328.44it/s]\u001b[A\n",
      " 24%|██▍       | 101277/414113 [00:23<01:12, 4324.01it/s]\u001b[A\n",
      " 25%|██▍       | 101710/414113 [00:23<01:12, 4305.08it/s]\u001b[A\n",
      " 25%|██▍       | 102155/414113 [00:23<01:11, 4345.19it/s]\u001b[A\n",
      " 25%|██▍       | 102599/414113 [00:24<01:11, 4372.15it/s]\u001b[A\n",
      " 25%|██▍       | 103050/414113 [00:24<01:10, 4410.36it/s]\u001b[A\n",
      " 25%|██▍       | 103495/414113 [00:24<01:10, 4419.11it/s]\u001b[A\n",
      " 25%|██▌       | 103938/414113 [00:24<01:11, 4351.14it/s]\u001b[A\n",
      " 25%|██▌       | 104374/414113 [00:24<01:12, 4293.99it/s]\u001b[A\n",
      " 25%|██▌       | 104804/414113 [00:24<01:12, 4278.96it/s]\u001b[A\n",
      " 25%|██▌       | 105233/414113 [00:24<01:12, 4250.93it/s]\u001b[A\n",
      " 26%|██▌       | 105661/414113 [00:24<01:12, 4259.07it/s]\u001b[A\n",
      " 26%|██▌       | 106094/414113 [00:24<01:11, 4278.40it/s]\u001b[A\n",
      " 26%|██▌       | 106522/414113 [00:24<01:11, 4276.84it/s]\u001b[A\n",
      " 26%|██▌       | 106956/414113 [00:25<01:11, 4294.44it/s]\u001b[A\n",
      " 26%|██▌       | 107386/414113 [00:25<01:12, 4208.96it/s]\u001b[A\n",
      " 26%|██▌       | 107821/414113 [00:25<01:12, 4249.30it/s]\u001b[A\n",
      " 26%|██▌       | 108247/414113 [00:25<01:12, 4244.53it/s]\u001b[A\n",
      " 26%|██▌       | 108675/414113 [00:25<01:11, 4254.70it/s]\u001b[A\n",
      " 26%|██▋       | 109101/414113 [00:25<01:12, 4223.91it/s]\u001b[A\n",
      " 26%|██▋       | 109524/414113 [00:25<01:12, 4193.01it/s]\u001b[A\n",
      " 27%|██▋       | 109952/414113 [00:25<01:12, 4215.54it/s]\u001b[A\n",
      " 27%|██▋       | 110384/414113 [00:25<01:11, 4244.22it/s]\u001b[A\n",
      " 27%|██▋       | 110817/414113 [00:25<01:11, 4269.41it/s]\u001b[A\n",
      " 27%|██▋       | 111264/414113 [00:26<01:10, 4325.88it/s]\u001b[A\n",
      " 27%|██▋       | 111700/414113 [00:26<01:09, 4333.88it/s]\u001b[A\n",
      " 27%|██▋       | 112134/414113 [00:26<01:09, 4326.48it/s]\u001b[A\n",
      " 27%|██▋       | 112568/414113 [00:26<01:09, 4327.87it/s]\u001b[A\n",
      " 27%|██▋       | 113001/414113 [00:26<01:10, 4299.70it/s]\u001b[A\n",
      " 27%|██▋       | 113432/414113 [00:26<01:10, 4262.71it/s]\u001b[A\n",
      " 27%|██▋       | 113859/414113 [00:26<01:10, 4240.90it/s]\u001b[A\n",
      " 28%|██▊       | 114284/414113 [00:26<01:10, 4228.46it/s]\u001b[A\n",
      " 28%|██▊       | 114708/414113 [00:26<01:10, 4229.58it/s]\u001b[A\n",
      " 28%|██▊       | 115137/414113 [00:26<01:10, 4245.72it/s]\u001b[A\n",
      " 28%|██▊       | 115573/414113 [00:27<01:09, 4278.92it/s]\u001b[A\n",
      " 28%|██▊       | 116001/414113 [00:27<01:09, 4266.98it/s]\u001b[A\n",
      " 28%|██▊       | 116440/414113 [00:27<01:09, 4302.48it/s]\u001b[A\n",
      " 28%|██▊       | 116885/414113 [00:27<01:08, 4344.85it/s]\u001b[A\n",
      " 28%|██▊       | 117320/414113 [00:27<01:08, 4312.36it/s]\u001b[A\n",
      " 28%|██▊       | 117752/414113 [00:27<01:08, 4313.94it/s]\u001b[A\n",
      " 29%|██▊       | 118184/414113 [00:27<01:09, 4275.81it/s]\u001b[A\n",
      " 29%|██▊       | 118615/414113 [00:27<01:08, 4284.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 119044/414113 [00:27<01:08, 4278.27it/s]\u001b[A\n",
      " 29%|██▉       | 119480/414113 [00:27<01:08, 4302.16it/s]\u001b[A\n",
      " 29%|██▉       | 119921/414113 [00:28<01:07, 4333.50it/s]\u001b[A\n",
      " 29%|██▉       | 120355/414113 [00:28<01:07, 4327.95it/s]\u001b[A\n",
      " 29%|██▉       | 120788/414113 [00:28<01:10, 4149.12it/s]\u001b[A\n",
      " 29%|██▉       | 121238/414113 [00:28<01:08, 4247.43it/s]\u001b[A\n",
      " 29%|██▉       | 121678/414113 [00:28<01:08, 4291.55it/s]\u001b[A\n",
      " 29%|██▉       | 122109/414113 [00:28<01:08, 4293.76it/s]\u001b[A\n",
      " 30%|██▉       | 122552/414113 [00:28<01:07, 4331.88it/s]\u001b[A\n",
      " 30%|██▉       | 122986/414113 [00:28<01:07, 4311.99it/s]\u001b[A\n",
      " 30%|██▉       | 123427/414113 [00:28<01:06, 4338.96it/s]\u001b[A\n",
      " 30%|██▉       | 123862/414113 [00:28<01:06, 4340.78it/s]\u001b[A\n",
      " 30%|███       | 124308/414113 [00:29<01:06, 4374.61it/s]\u001b[A\n",
      " 30%|███       | 124746/414113 [00:29<01:07, 4292.98it/s]\u001b[A\n",
      " 30%|███       | 125192/414113 [00:29<01:06, 4341.13it/s]\u001b[A\n",
      " 30%|███       | 125631/414113 [00:29<01:06, 4354.37it/s]\u001b[A\n",
      " 30%|███       | 126067/414113 [00:29<01:06, 4308.67it/s]\u001b[A\n",
      " 31%|███       | 126499/414113 [00:29<01:07, 4288.26it/s]\u001b[A\n",
      " 31%|███       | 126932/414113 [00:29<01:06, 4300.59it/s]\u001b[A\n",
      " 31%|███       | 127364/414113 [00:29<01:06, 4305.59it/s]\u001b[A\n",
      " 31%|███       | 127795/414113 [00:29<01:06, 4288.02it/s]\u001b[A\n",
      " 31%|███       | 128245/414113 [00:29<01:05, 4348.75it/s]\u001b[A\n",
      " 31%|███       | 128681/414113 [00:30<01:05, 4333.11it/s]\u001b[A\n",
      " 31%|███       | 129119/414113 [00:30<01:05, 4346.79it/s]\u001b[A\n",
      " 31%|███▏      | 129565/414113 [00:30<01:05, 4377.41it/s]\u001b[A\n",
      " 31%|███▏      | 130004/414113 [00:30<01:04, 4381.01it/s]\u001b[A\n",
      " 31%|███▏      | 130443/414113 [00:30<01:05, 4348.54it/s]\u001b[A\n",
      " 32%|███▏      | 130878/414113 [00:30<01:05, 4344.81it/s]\u001b[A\n",
      " 32%|███▏      | 131313/414113 [00:30<01:05, 4337.75it/s]\u001b[A\n",
      " 32%|███▏      | 131748/414113 [00:30<01:05, 4341.02it/s]\u001b[A\n",
      " 32%|███▏      | 132183/414113 [00:30<01:05, 4299.48it/s]\u001b[A\n",
      " 32%|███▏      | 132614/414113 [00:30<01:05, 4275.10it/s]\u001b[A\n",
      " 32%|███▏      | 133044/414113 [00:31<01:05, 4281.10it/s]\u001b[A\n",
      " 32%|███▏      | 133486/414113 [00:31<01:04, 4318.14it/s]\u001b[A\n",
      " 32%|███▏      | 133918/414113 [00:31<01:05, 4306.97it/s]\u001b[A\n",
      " 32%|███▏      | 134349/414113 [00:31<01:05, 4296.92it/s]\u001b[A\n",
      " 33%|███▎      | 134797/414113 [00:31<01:04, 4347.29it/s]\u001b[A\n",
      " 33%|███▎      | 135232/414113 [00:31<01:04, 4341.57it/s]\u001b[A\n",
      " 33%|███▎      | 135674/414113 [00:31<01:03, 4362.60it/s]\u001b[A\n",
      " 33%|███▎      | 136111/414113 [00:31<01:03, 4345.15it/s]\u001b[A\n",
      " 33%|███▎      | 136552/414113 [00:31<01:03, 4363.39it/s]\u001b[A\n",
      " 33%|███▎      | 136989/414113 [00:31<01:03, 4354.84it/s]\u001b[A\n",
      " 33%|███▎      | 137440/414113 [00:32<01:02, 4399.68it/s]\u001b[A\n",
      " 33%|███▎      | 137883/414113 [00:32<01:02, 4407.52it/s]\u001b[A\n",
      " 33%|███▎      | 138324/414113 [00:32<01:02, 4403.86it/s]\u001b[A\n",
      " 34%|███▎      | 138765/414113 [00:32<01:02, 4395.68it/s]\u001b[A\n",
      " 34%|███▎      | 139219/414113 [00:32<01:01, 4436.25it/s]\u001b[A\n",
      " 34%|███▎      | 139663/414113 [00:32<01:02, 4415.91it/s]\u001b[A\n",
      " 34%|███▍      | 140105/414113 [00:32<01:02, 4392.03it/s]\u001b[A\n",
      " 34%|███▍      | 140545/414113 [00:32<01:02, 4361.52it/s]\u001b[A\n",
      " 34%|███▍      | 140982/414113 [00:32<01:02, 4343.24it/s]\u001b[A\n",
      " 34%|███▍      | 141417/414113 [00:33<01:03, 4290.06it/s]\u001b[A\n",
      " 34%|███▍      | 141852/414113 [00:33<01:03, 4307.32it/s]\u001b[A\n",
      " 34%|███▍      | 142283/414113 [00:33<01:10, 3850.01it/s]\u001b[A\n",
      " 34%|███▍      | 142721/414113 [00:33<01:07, 3993.38it/s]\u001b[A\n",
      " 35%|███▍      | 143160/414113 [00:33<01:06, 4102.11it/s]\u001b[A\n",
      " 35%|███▍      | 143607/414113 [00:33<01:04, 4205.49it/s]\u001b[A\n",
      " 35%|███▍      | 144041/414113 [00:33<01:03, 4244.26it/s]\u001b[A\n",
      " 35%|███▍      | 144486/414113 [00:33<01:02, 4301.26it/s]\u001b[A\n",
      " 35%|███▍      | 144922/414113 [00:33<01:02, 4318.61it/s]\u001b[A\n",
      " 35%|███▌      | 145373/414113 [00:33<01:01, 4373.60it/s]\u001b[A\n",
      " 35%|███▌      | 145821/414113 [00:34<01:00, 4404.06it/s]\u001b[A\n",
      " 35%|███▌      | 146263/414113 [00:34<01:01, 4365.43it/s]\u001b[A\n",
      " 35%|███▌      | 146701/414113 [00:34<01:01, 4355.38it/s]\u001b[A\n",
      " 36%|███▌      | 147138/414113 [00:34<01:04, 4162.95it/s]\u001b[A\n",
      " 36%|███▌      | 147574/414113 [00:34<01:03, 4217.94it/s]\u001b[A\n",
      " 36%|███▌      | 148017/414113 [00:34<01:02, 4277.00it/s]\u001b[A\n",
      " 36%|███▌      | 148447/414113 [00:34<01:02, 4261.64it/s]\u001b[A\n",
      " 36%|███▌      | 148879/414113 [00:34<01:02, 4277.81it/s]\u001b[A\n",
      " 36%|███▌      | 149313/414113 [00:34<01:01, 4293.62it/s]\u001b[A\n",
      " 36%|███▌      | 149757/414113 [00:34<01:00, 4336.24it/s]\u001b[A\n",
      " 36%|███▋      | 150198/414113 [00:35<01:00, 4356.78it/s]\u001b[A\n",
      " 36%|███▋      | 150641/414113 [00:35<01:00, 4378.35it/s]\u001b[A\n",
      " 36%|███▋      | 151085/414113 [00:35<00:59, 4395.37it/s]\u001b[A\n",
      " 37%|███▋      | 151525/414113 [00:35<01:00, 4371.76it/s]\u001b[A\n",
      " 37%|███▋      | 151963/414113 [00:35<01:00, 4316.61it/s]\u001b[A\n",
      " 37%|███▋      | 152401/414113 [00:35<01:00, 4333.91it/s]\u001b[A\n",
      " 37%|███▋      | 152842/414113 [00:35<00:59, 4355.56it/s]\u001b[A\n",
      " 37%|███▋      | 153283/414113 [00:35<00:59, 4370.74it/s]\u001b[A\n",
      " 37%|███▋      | 153729/414113 [00:35<00:59, 4396.16it/s]\u001b[A\n",
      " 37%|███▋      | 154186/414113 [00:35<00:58, 4445.65it/s]\u001b[A\n",
      " 37%|███▋      | 154631/414113 [00:36<00:58, 4423.34it/s]\u001b[A\n",
      " 37%|███▋      | 155074/414113 [00:36<00:58, 4404.44it/s]\u001b[A\n",
      " 38%|███▊      | 155515/414113 [00:36<00:59, 4369.95it/s]\u001b[A\n",
      " 38%|███▊      | 155958/414113 [00:36<00:58, 4387.27it/s]\u001b[A\n",
      " 38%|███▊      | 156399/414113 [00:36<00:58, 4391.45it/s]\u001b[A\n",
      " 38%|███▊      | 156839/414113 [00:36<00:58, 4381.59it/s]\u001b[A\n",
      " 38%|███▊      | 157278/414113 [00:36<00:58, 4378.23it/s]\u001b[A\n",
      " 38%|███▊      | 157716/414113 [00:36<00:58, 4356.97it/s]\u001b[A\n",
      " 38%|███▊      | 158162/414113 [00:36<00:58, 4384.34it/s]\u001b[A\n",
      " 38%|███▊      | 158601/414113 [00:36<00:58, 4346.33it/s]\u001b[A\n",
      " 38%|███▊      | 159054/414113 [00:37<00:58, 4397.55it/s]\u001b[A\n",
      " 39%|███▊      | 159494/414113 [00:37<00:58, 4387.37it/s]\u001b[A\n",
      " 39%|███▊      | 159943/414113 [00:37<00:57, 4416.61it/s]\u001b[A\n",
      " 39%|███▊      | 160385/414113 [00:37<00:57, 4401.33it/s]\u001b[A\n",
      " 39%|███▉      | 160827/414113 [00:37<00:57, 4405.31it/s]\u001b[A\n",
      " 39%|███▉      | 161276/414113 [00:37<00:57, 4429.61it/s]\u001b[A\n",
      " 39%|███▉      | 161720/414113 [00:37<00:57, 4419.75it/s]\u001b[A\n",
      " 39%|███▉      | 162163/414113 [00:37<00:57, 4414.12it/s]\u001b[A\n",
      " 39%|███▉      | 162619/414113 [00:37<00:56, 4456.32it/s]\u001b[A\n",
      " 39%|███▉      | 163065/414113 [00:37<00:56, 4408.60it/s]\u001b[A\n",
      " 39%|███▉      | 163519/414113 [00:38<00:56, 4446.14it/s]\u001b[A\n",
      " 40%|███▉      | 163964/414113 [00:38<00:56, 4416.13it/s]\u001b[A\n",
      " 40%|███▉      | 164406/414113 [00:38<00:56, 4399.87it/s]\u001b[A\n",
      " 40%|███▉      | 164847/414113 [00:38<00:57, 4366.36it/s]\u001b[A\n",
      " 40%|███▉      | 165284/414113 [00:38<00:57, 4359.77it/s]\u001b[A\n",
      " 40%|████      | 165721/414113 [00:38<00:57, 4326.17it/s]\u001b[A\n",
      " 40%|████      | 166154/414113 [00:38<00:57, 4305.78it/s]\u001b[A\n",
      " 40%|████      | 166585/414113 [00:38<00:58, 4222.25it/s]\u001b[A\n",
      " 40%|████      | 167021/414113 [00:38<00:58, 4258.93it/s]\u001b[A\n",
      " 40%|████      | 167448/414113 [00:39<00:58, 4198.80it/s]\u001b[A\n",
      " 41%|████      | 167881/414113 [00:39<00:58, 4237.11it/s]\u001b[A\n",
      " 41%|████      | 168306/414113 [00:39<00:58, 4189.23it/s]\u001b[A\n",
      " 41%|████      | 168744/414113 [00:39<00:57, 4242.85it/s]\u001b[A\n",
      " 41%|████      | 169169/414113 [00:39<00:58, 4206.49it/s]\u001b[A\n",
      " 41%|████      | 169606/414113 [00:39<00:57, 4252.08it/s]\u001b[A\n",
      " 41%|████      | 170042/414113 [00:39<00:56, 4281.95it/s]\u001b[A\n",
      " 41%|████      | 170471/414113 [00:39<00:57, 4274.11it/s]\u001b[A\n",
      " 41%|████▏     | 170899/414113 [00:39<00:56, 4269.74it/s]\u001b[A\n",
      " 41%|████▏     | 171327/414113 [00:39<00:57, 4252.38it/s]\u001b[A\n",
      " 41%|████▏     | 171765/414113 [00:40<00:56, 4289.15it/s]\u001b[A\n",
      " 42%|████▏     | 172196/414113 [00:40<00:56, 4291.80it/s]\u001b[A\n",
      " 42%|████▏     | 172626/414113 [00:40<00:56, 4253.26it/s]\u001b[A\n",
      " 42%|████▏     | 173052/414113 [00:40<00:57, 4184.22it/s]\u001b[A\n",
      " 42%|████▏     | 173476/414113 [00:40<00:57, 4199.81it/s]\u001b[A\n",
      " 42%|████▏     | 173897/414113 [00:40<00:57, 4192.96it/s]\u001b[A\n",
      " 42%|████▏     | 174322/414113 [00:40<00:56, 4209.63it/s]\u001b[A\n",
      " 42%|████▏     | 174744/414113 [00:40<01:36, 2482.27it/s]\u001b[A\n",
      " 42%|████▏     | 175161/414113 [00:41<01:24, 2824.69it/s]\u001b[A\n",
      " 42%|████▏     | 175580/414113 [00:41<01:16, 3130.52it/s]\u001b[A\n",
      " 43%|████▎     | 176012/414113 [00:41<01:09, 3411.53it/s]\u001b[A\n",
      " 43%|████▎     | 176442/414113 [00:41<01:05, 3635.13it/s]\u001b[A\n",
      " 43%|████▎     | 176877/414113 [00:41<01:02, 3821.81it/s]\u001b[A\n",
      " 43%|████▎     | 177306/414113 [00:41<00:59, 3948.77it/s]\u001b[A\n",
      " 43%|████▎     | 177737/414113 [00:41<00:58, 4050.43it/s]\u001b[A\n",
      " 43%|████▎     | 178169/414113 [00:41<00:57, 4125.46it/s]\u001b[A\n",
      " 43%|████▎     | 178595/414113 [00:41<00:56, 4162.32it/s]\u001b[A\n",
      " 43%|████▎     | 179023/414113 [00:41<00:56, 4193.95it/s]\u001b[A\n",
      " 43%|████▎     | 179461/414113 [00:42<00:55, 4248.01it/s]\u001b[A\n",
      " 43%|████▎     | 179891/414113 [00:42<00:55, 4245.23it/s]\u001b[A\n",
      " 44%|████▎     | 180319/414113 [00:42<00:55, 4224.58it/s]\u001b[A\n",
      " 44%|████▎     | 180750/414113 [00:42<00:54, 4248.78it/s]\u001b[A\n",
      " 44%|████▍     | 181181/414113 [00:42<00:54, 4266.06it/s]\u001b[A\n",
      " 44%|████▍     | 181621/414113 [00:42<00:54, 4303.64it/s]\u001b[A\n",
      " 44%|████▍     | 182053/414113 [00:42<00:53, 4302.28it/s]\u001b[A\n",
      " 44%|████▍     | 182484/414113 [00:42<00:53, 4298.92it/s]\u001b[A\n",
      " 44%|████▍     | 182915/414113 [00:42<00:55, 4198.34it/s]\u001b[A\n",
      " 44%|████▍     | 183349/414113 [00:42<00:54, 4237.36it/s]\u001b[A\n",
      " 44%|████▍     | 183779/414113 [00:43<00:54, 4255.62it/s]\u001b[A\n",
      " 44%|████▍     | 184223/414113 [00:43<00:53, 4307.96it/s]\u001b[A\n",
      " 45%|████▍     | 184655/414113 [00:43<00:53, 4308.45it/s]\u001b[A\n",
      " 45%|████▍     | 185089/414113 [00:43<00:53, 4314.85it/s]\u001b[A\n",
      " 45%|████▍     | 185537/414113 [00:43<00:52, 4360.11it/s]\u001b[A\n",
      " 45%|████▍     | 185974/414113 [00:43<00:53, 4297.07it/s]\u001b[A\n",
      " 45%|████▌     | 186408/414113 [00:43<00:52, 4309.67it/s]\u001b[A\n",
      " 45%|████▌     | 186847/414113 [00:43<00:52, 4331.54it/s]\u001b[A\n",
      " 45%|████▌     | 187281/414113 [00:43<00:52, 4313.38it/s]\u001b[A\n",
      " 45%|████▌     | 187716/414113 [00:43<00:52, 4323.80it/s]\u001b[A\n",
      " 45%|████▌     | 188149/414113 [00:44<00:52, 4293.27it/s]\u001b[A\n",
      " 46%|████▌     | 188580/414113 [00:44<00:52, 4297.53it/s]\u001b[A\n",
      " 46%|████▌     | 189010/414113 [00:44<00:52, 4295.88it/s]\u001b[A\n",
      " 46%|████▌     | 189445/414113 [00:44<00:52, 4310.81it/s]\u001b[A\n",
      " 46%|████▌     | 189878/414113 [00:44<00:51, 4314.15it/s]\u001b[A\n",
      " 46%|████▌     | 190310/414113 [00:44<00:53, 4166.71it/s]\u001b[A\n",
      " 46%|████▌     | 190750/414113 [00:44<00:52, 4232.02it/s]\u001b[A\n",
      " 46%|████▌     | 191175/414113 [00:44<00:53, 4185.40it/s]\u001b[A\n",
      " 46%|████▋     | 191612/414113 [00:44<00:52, 4238.12it/s]\u001b[A\n",
      " 46%|████▋     | 192040/414113 [00:45<00:52, 4248.48it/s]\u001b[A\n",
      " 46%|████▋     | 192480/414113 [00:45<00:51, 4292.30it/s]\u001b[A\n",
      " 47%|████▋     | 192910/414113 [00:45<00:52, 4224.55it/s]\u001b[A\n",
      " 47%|████▋     | 193334/414113 [00:45<00:52, 4229.05it/s]\u001b[A\n",
      " 47%|████▋     | 193771/414113 [00:45<00:51, 4267.97it/s]\u001b[A\n",
      " 47%|████▋     | 194199/414113 [00:45<00:52, 4186.64it/s]\u001b[A\n",
      " 47%|████▋     | 194631/414113 [00:45<00:51, 4225.32it/s]\u001b[A\n",
      " 47%|████▋     | 195062/414113 [00:45<00:51, 4250.17it/s]\u001b[A\n",
      " 47%|████▋     | 195501/414113 [00:45<00:50, 4290.58it/s]\u001b[A\n",
      " 47%|████▋     | 195931/414113 [00:45<00:50, 4288.54it/s]\u001b[A\n",
      " 47%|████▋     | 196383/414113 [00:46<00:50, 4353.64it/s]\u001b[A\n",
      " 48%|████▊     | 196819/414113 [00:46<00:50, 4335.15it/s]\u001b[A\n",
      " 48%|████▊     | 197259/414113 [00:46<00:49, 4353.13it/s]\u001b[A\n",
      " 48%|████▊     | 197708/414113 [00:46<00:49, 4391.07it/s]\u001b[A\n",
      " 48%|████▊     | 198148/414113 [00:46<00:49, 4336.96it/s]\u001b[A\n",
      " 48%|████▊     | 198591/414113 [00:46<00:49, 4364.43it/s]\u001b[A\n",
      " 48%|████▊     | 199028/414113 [00:46<00:49, 4321.84it/s]\u001b[A\n",
      " 48%|████▊     | 199461/414113 [00:46<00:50, 4274.21it/s]\u001b[A\n",
      " 48%|████▊     | 199899/414113 [00:46<00:49, 4305.25it/s]\u001b[A\n",
      " 48%|████▊     | 200341/414113 [00:46<00:49, 4338.39it/s]\u001b[A\n",
      " 48%|████▊     | 200795/414113 [00:47<00:48, 4395.52it/s]\u001b[A\n",
      " 49%|████▊     | 201235/414113 [00:47<00:48, 4365.13it/s]\u001b[A\n",
      " 49%|████▊     | 201672/414113 [00:47<00:49, 4331.45it/s]\u001b[A\n",
      " 49%|████▉     | 202124/414113 [00:47<00:48, 4385.61it/s]\u001b[A\n",
      " 49%|████▉     | 202563/414113 [00:47<00:48, 4378.59it/s]\u001b[A\n",
      " 49%|████▉     | 203002/414113 [00:47<00:48, 4379.80it/s]\u001b[A\n",
      " 49%|████▉     | 203445/414113 [00:47<00:47, 4394.54it/s]\u001b[A\n",
      " 49%|████▉     | 203889/414113 [00:47<00:47, 4406.09it/s]\u001b[A\n",
      " 49%|████▉     | 204330/414113 [00:47<00:47, 4393.68it/s]\u001b[A\n",
      " 49%|████▉     | 204777/414113 [00:47<00:47, 4413.93it/s]\u001b[A\n",
      " 50%|████▉     | 205221/414113 [00:48<00:47, 4421.10it/s]\u001b[A\n",
      " 50%|████▉     | 205664/414113 [00:48<00:47, 4415.27it/s]\u001b[A\n",
      " 50%|████▉     | 206106/414113 [00:48<00:47, 4406.15it/s]\u001b[A\n",
      " 50%|████▉     | 206549/414113 [00:48<00:47, 4410.71it/s]\u001b[A\n",
      " 50%|████▉     | 206991/414113 [00:48<00:47, 4403.00it/s]\u001b[A\n",
      " 50%|█████     | 207434/414113 [00:48<00:46, 4409.32it/s]\u001b[A\n",
      " 50%|█████     | 207875/414113 [00:48<00:47, 4354.58it/s]\u001b[A\n",
      " 50%|█████     | 208315/414113 [00:48<00:47, 4364.18it/s]\u001b[A\n",
      " 50%|█████     | 208752/414113 [00:48<00:47, 4317.44it/s]\u001b[A\n",
      " 51%|█████     | 209185/414113 [00:48<00:47, 4320.05it/s]\u001b[A\n",
      " 51%|█████     | 209618/414113 [00:49<00:47, 4306.78it/s]\u001b[A\n",
      " 51%|█████     | 210058/414113 [00:49<00:47, 4332.83it/s]\u001b[A\n",
      " 51%|█████     | 210492/414113 [00:49<00:47, 4330.77it/s]\u001b[A\n",
      " 51%|█████     | 210936/414113 [00:49<00:46, 4360.41it/s]\u001b[A\n",
      " 51%|█████     | 211373/414113 [00:49<00:46, 4361.74it/s]\u001b[A\n",
      " 51%|█████     | 211821/414113 [00:49<00:46, 4395.29it/s]\u001b[A\n",
      " 51%|█████▏    | 212261/414113 [00:49<00:46, 4380.81it/s]\u001b[A\n",
      " 51%|█████▏    | 212700/414113 [00:49<00:46, 4354.16it/s]\u001b[A\n",
      " 51%|█████▏    | 213136/414113 [00:49<00:46, 4343.65it/s]\u001b[A\n",
      " 52%|█████▏    | 213571/414113 [00:49<00:46, 4339.68it/s]\u001b[A\n",
      " 52%|█████▏    | 214016/414113 [00:50<00:45, 4371.46it/s]\u001b[A\n",
      " 52%|█████▏    | 214454/414113 [00:50<00:45, 4366.74it/s]\u001b[A\n",
      " 52%|█████▏    | 214900/414113 [00:50<00:45, 4392.34it/s]\u001b[A\n",
      " 52%|█████▏    | 215340/414113 [00:50<00:45, 4372.77it/s]\u001b[A\n",
      " 52%|█████▏    | 215780/414113 [00:50<00:45, 4380.64it/s]\u001b[A\n",
      " 52%|█████▏    | 216219/414113 [00:50<00:45, 4340.20it/s]\u001b[A\n",
      " 52%|█████▏    | 216654/414113 [00:50<00:45, 4301.99it/s]\u001b[A\n",
      " 52%|█████▏    | 217086/414113 [00:50<00:45, 4306.95it/s]\u001b[A\n",
      " 53%|█████▎    | 217521/414113 [00:50<00:45, 4318.52it/s]\u001b[A\n",
      " 53%|█████▎    | 217966/414113 [00:50<00:45, 4355.98it/s]\u001b[A\n",
      " 53%|█████▎    | 218426/414113 [00:51<00:44, 4423.25it/s]\u001b[A\n",
      " 53%|█████▎    | 218879/414113 [00:51<00:43, 4454.07it/s]\u001b[A\n",
      " 53%|█████▎    | 219331/414113 [00:51<00:43, 4472.54it/s]\u001b[A\n",
      " 53%|█████▎    | 219779/414113 [00:51<00:43, 4436.96it/s]\u001b[A\n",
      " 53%|█████▎    | 220229/414113 [00:51<00:43, 4454.67it/s]\u001b[A\n",
      " 53%|█████▎    | 220675/414113 [00:51<00:43, 4434.00it/s]\u001b[A\n",
      " 53%|█████▎    | 221119/414113 [00:51<00:43, 4427.00it/s]\u001b[A\n",
      " 54%|█████▎    | 221562/414113 [00:51<00:43, 4406.36it/s]\u001b[A\n",
      " 54%|█████▎    | 222012/414113 [00:51<00:43, 4431.92it/s]\u001b[A\n",
      " 54%|█████▎    | 222468/414113 [00:51<00:42, 4466.78it/s]\u001b[A\n",
      " 54%|█████▍    | 222915/414113 [00:52<00:43, 4439.55it/s]\u001b[A\n",
      " 54%|█████▍    | 223360/414113 [00:52<00:42, 4440.29it/s]\u001b[A\n",
      " 54%|█████▍    | 223812/414113 [00:52<00:42, 4463.18it/s]\u001b[A\n",
      " 54%|█████▍    | 224259/414113 [00:52<00:42, 4459.97it/s]\u001b[A\n",
      " 54%|█████▍    | 224706/414113 [00:52<00:45, 4129.24it/s]\u001b[A\n",
      " 54%|█████▍    | 225150/414113 [00:52<00:44, 4217.10it/s]\u001b[A\n",
      " 54%|█████▍    | 225595/414113 [00:52<00:44, 4282.94it/s]\u001b[A\n",
      " 55%|█████▍    | 226027/414113 [00:52<00:44, 4260.67it/s]\u001b[A\n",
      " 55%|█████▍    | 226473/414113 [00:52<00:43, 4318.05it/s]\u001b[A\n",
      " 55%|█████▍    | 226926/414113 [00:53<00:42, 4377.16it/s]\u001b[A\n",
      " 55%|█████▍    | 227366/414113 [00:53<00:43, 4336.24it/s]\u001b[A\n",
      " 55%|█████▌    | 227827/414113 [00:53<00:42, 4412.58it/s]\u001b[A\n",
      " 55%|█████▌    | 228270/414113 [00:53<00:42, 4417.08it/s]\u001b[A\n",
      " 55%|█████▌    | 228716/414113 [00:53<00:41, 4428.49it/s]\u001b[A\n",
      " 55%|█████▌    | 229160/414113 [00:53<00:41, 4405.53it/s]\u001b[A\n",
      " 55%|█████▌    | 229601/414113 [00:53<00:42, 4386.91it/s]\u001b[A\n",
      " 56%|█████▌    | 230045/414113 [00:53<00:41, 4400.28it/s]\u001b[A\n",
      " 56%|█████▌    | 230486/414113 [00:53<00:42, 4296.11it/s]\u001b[A\n",
      " 56%|█████▌    | 230927/414113 [00:53<00:42, 4326.99it/s]\u001b[A\n",
      " 56%|█████▌    | 231371/414113 [00:54<00:41, 4360.14it/s]\u001b[A\n",
      " 56%|█████▌    | 231808/414113 [00:54<00:42, 4303.52it/s]\u001b[A\n",
      " 56%|█████▌    | 232241/414113 [00:54<00:42, 4307.88it/s]\u001b[A\n",
      " 56%|█████▌    | 232673/414113 [00:54<00:42, 4303.41it/s]\u001b[A\n",
      " 56%|█████▋    | 233104/414113 [00:54<00:42, 4280.82it/s]\u001b[A\n",
      " 56%|█████▋    | 233542/414113 [00:54<00:41, 4308.48it/s]\u001b[A\n",
      " 57%|█████▋    | 233985/414113 [00:54<00:41, 4341.25it/s]\u001b[A\n",
      " 57%|█████▋    | 234425/414113 [00:54<00:41, 4355.89it/s]\u001b[A\n",
      " 57%|█████▋    | 234861/414113 [00:54<00:41, 4324.87it/s]\u001b[A\n",
      " 57%|█████▋    | 235294/414113 [00:54<00:41, 4324.39it/s]\u001b[A\n",
      " 57%|█████▋    | 235733/414113 [00:55<00:41, 4342.78it/s]\u001b[A\n",
      " 57%|█████▋    | 236168/414113 [00:55<00:41, 4336.73it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 236602/414113 [00:55<00:41, 4297.74it/s]\u001b[A\n",
      " 57%|█████▋    | 237032/414113 [00:55<00:41, 4216.83it/s]\u001b[A\n",
      " 57%|█████▋    | 237469/414113 [00:55<00:41, 4260.04it/s]\u001b[A\n",
      " 57%|█████▋    | 237896/414113 [00:55<00:41, 4256.96it/s]\u001b[A\n",
      " 58%|█████▊    | 238322/414113 [00:55<00:41, 4253.87it/s]\u001b[A\n",
      " 58%|█████▊    | 238761/414113 [00:55<00:40, 4292.31it/s]\u001b[A\n",
      " 58%|█████▊    | 239191/414113 [00:55<00:40, 4273.27it/s]\u001b[A\n",
      " 58%|█████▊    | 239619/414113 [00:55<00:41, 4177.69it/s]\u001b[A\n",
      " 58%|█████▊    | 240053/414113 [00:56<00:41, 4223.49it/s]\u001b[A\n",
      " 58%|█████▊    | 240476/414113 [00:56<00:41, 4222.31it/s]\u001b[A\n",
      " 58%|█████▊    | 240899/414113 [00:56<00:41, 4167.30it/s]\u001b[A\n",
      " 58%|█████▊    | 241329/414113 [00:56<00:41, 4205.33it/s]\u001b[A\n",
      " 58%|█████▊    | 241762/414113 [00:56<00:40, 4240.41it/s]\u001b[A\n",
      " 58%|█████▊    | 242203/414113 [00:56<00:40, 4288.62it/s]\u001b[A\n",
      " 59%|█████▊    | 242637/414113 [00:56<00:39, 4303.62it/s]\u001b[A\n",
      " 59%|█████▊    | 243068/414113 [00:56<00:39, 4297.65it/s]\u001b[A\n",
      " 59%|█████▉    | 243506/414113 [00:56<00:39, 4321.10it/s]\u001b[A\n",
      " 59%|█████▉    | 243939/414113 [00:56<00:39, 4311.74it/s]\u001b[A\n",
      " 59%|█████▉    | 244371/414113 [00:57<00:39, 4302.02it/s]\u001b[A\n",
      " 59%|█████▉    | 244802/414113 [00:57<00:39, 4292.91it/s]\u001b[A\n",
      " 59%|█████▉    | 245243/414113 [00:57<00:39, 4326.61it/s]\u001b[A\n",
      " 59%|█████▉    | 245676/414113 [00:57<00:39, 4298.39it/s]\u001b[A\n",
      " 59%|█████▉    | 246111/414113 [00:57<00:38, 4310.80it/s]\u001b[A\n",
      " 60%|█████▉    | 246548/414113 [00:57<00:38, 4326.08it/s]\u001b[A\n",
      " 60%|█████▉    | 246983/414113 [00:57<00:38, 4331.28it/s]\u001b[A\n",
      " 60%|█████▉    | 247421/414113 [00:57<00:38, 4343.09it/s]\u001b[A\n",
      " 60%|█████▉    | 247856/414113 [00:57<00:38, 4330.68it/s]\u001b[A\n",
      " 60%|█████▉    | 248291/414113 [00:57<00:38, 4335.76it/s]\u001b[A\n",
      " 60%|██████    | 248729/414113 [00:58<00:38, 4346.01it/s]\u001b[A\n",
      " 60%|██████    | 249165/414113 [00:58<00:37, 4347.72it/s]\u001b[A\n",
      " 60%|██████    | 249600/414113 [00:58<00:38, 4327.00it/s]\u001b[A\n",
      " 60%|██████    | 250033/414113 [00:58<00:38, 4307.25it/s]\u001b[A\n",
      " 60%|██████    | 250464/414113 [00:58<00:38, 4305.49it/s]\u001b[A\n",
      " 61%|██████    | 250897/414113 [00:58<00:37, 4310.45it/s]\u001b[A\n",
      " 61%|██████    | 251329/414113 [00:58<00:37, 4308.67it/s]\u001b[A\n",
      " 61%|██████    | 251775/414113 [00:58<00:37, 4350.94it/s]\u001b[A\n",
      " 61%|██████    | 252226/414113 [00:58<00:36, 4395.95it/s]\u001b[A\n",
      " 61%|██████    | 252669/414113 [00:58<00:36, 4405.29it/s]\u001b[A\n",
      " 61%|██████    | 253110/414113 [00:59<00:36, 4376.29it/s]\u001b[A\n",
      " 61%|██████    | 253548/414113 [00:59<00:37, 4313.51it/s]\u001b[A\n",
      " 61%|██████▏   | 253993/414113 [00:59<00:36, 4350.99it/s]\u001b[A\n",
      " 61%|██████▏   | 254429/414113 [00:59<00:36, 4352.07it/s]\u001b[A\n",
      " 62%|██████▏   | 254865/414113 [00:59<00:37, 4280.73it/s]\u001b[A\n",
      " 62%|██████▏   | 255301/414113 [00:59<00:36, 4302.36it/s]\u001b[A\n",
      " 62%|██████▏   | 255732/414113 [00:59<00:36, 4299.40it/s]\u001b[A\n",
      " 62%|██████▏   | 256176/414113 [00:59<00:36, 4337.66it/s]\u001b[A\n",
      " 62%|██████▏   | 256617/414113 [00:59<00:36, 4358.45it/s]\u001b[A\n",
      " 62%|██████▏   | 257058/414113 [01:00<00:35, 4371.60it/s]\u001b[A\n",
      " 62%|██████▏   | 257502/414113 [01:00<00:35, 4388.88it/s]\u001b[A\n",
      " 62%|██████▏   | 257942/414113 [01:00<00:36, 4336.89it/s]\u001b[A\n",
      " 62%|██████▏   | 258376/414113 [01:00<00:36, 4306.60it/s]\u001b[A\n",
      " 62%|██████▏   | 258813/414113 [01:00<00:35, 4324.32it/s]\u001b[A\n",
      " 63%|██████▎   | 259246/414113 [01:00<00:36, 4295.17it/s]\u001b[A\n",
      " 63%|██████▎   | 259689/414113 [01:00<00:35, 4332.31it/s]\u001b[A\n",
      " 63%|██████▎   | 260124/414113 [01:00<00:35, 4334.75it/s]\u001b[A\n",
      " 63%|██████▎   | 260563/414113 [01:00<00:35, 4350.83it/s]\u001b[A\n",
      " 63%|██████▎   | 261010/414113 [01:00<00:34, 4385.57it/s]\u001b[A\n",
      " 63%|██████▎   | 261459/414113 [01:01<00:34, 4413.86it/s]\u001b[A\n",
      " 63%|██████▎   | 261902/414113 [01:01<00:34, 4416.08it/s]\u001b[A\n",
      " 63%|██████▎   | 262344/414113 [01:01<00:34, 4407.95it/s]\u001b[A\n",
      " 63%|██████▎   | 262785/414113 [01:01<00:34, 4381.49it/s]\u001b[A\n",
      " 64%|██████▎   | 263226/414113 [01:01<00:34, 4387.78it/s]\u001b[A\n",
      " 64%|██████▎   | 263669/414113 [01:01<00:34, 4399.35it/s]\u001b[A\n",
      " 64%|██████▍   | 264109/414113 [01:01<00:34, 4337.25it/s]\u001b[A\n",
      " 64%|██████▍   | 264543/414113 [01:01<00:34, 4309.11it/s]\u001b[A\n",
      " 64%|██████▍   | 264975/414113 [01:01<00:34, 4291.06it/s]\u001b[A\n",
      " 64%|██████▍   | 265405/414113 [01:01<00:34, 4278.69it/s]\u001b[A\n",
      " 64%|██████▍   | 265841/414113 [01:02<00:34, 4300.39it/s]\u001b[A\n",
      " 64%|██████▍   | 266273/414113 [01:02<00:34, 4304.16it/s]\u001b[A\n",
      " 64%|██████▍   | 266716/414113 [01:02<00:33, 4338.98it/s]\u001b[A\n",
      " 65%|██████▍   | 267151/414113 [01:02<00:33, 4323.75it/s]\u001b[A\n",
      " 65%|██████▍   | 267595/414113 [01:02<00:33, 4357.58it/s]\u001b[A\n",
      " 65%|██████▍   | 268036/414113 [01:02<00:33, 4372.57it/s]\u001b[A\n",
      " 65%|██████▍   | 268474/414113 [01:02<00:33, 4341.40it/s]\u001b[A\n",
      " 65%|██████▍   | 268909/414113 [01:02<00:33, 4334.61it/s]\u001b[A\n",
      " 65%|██████▌   | 269343/414113 [01:02<00:33, 4335.54it/s]\u001b[A\n",
      " 65%|██████▌   | 269783/414113 [01:02<00:33, 4353.28it/s]\u001b[A\n",
      " 65%|██████▌   | 270219/414113 [01:03<00:33, 4340.06it/s]\u001b[A\n",
      " 65%|██████▌   | 270656/414113 [01:03<00:32, 4348.72it/s]\u001b[A\n",
      " 65%|██████▌   | 271104/414113 [01:03<00:32, 4385.47it/s]\u001b[A\n",
      " 66%|██████▌   | 271543/414113 [01:03<00:32, 4363.94it/s]\u001b[A\n",
      " 66%|██████▌   | 271980/414113 [01:03<00:32, 4333.40it/s]\u001b[A\n",
      " 66%|██████▌   | 272414/414113 [01:03<00:32, 4319.29it/s]\u001b[A\n",
      " 66%|██████▌   | 272856/414113 [01:03<00:32, 4346.71it/s]\u001b[A\n",
      " 66%|██████▌   | 273291/414113 [01:03<00:32, 4330.60it/s]\u001b[A\n",
      " 66%|██████▌   | 273725/414113 [01:03<00:32, 4321.79it/s]\u001b[A\n",
      " 66%|██████▌   | 274159/414113 [01:03<00:32, 4324.36it/s]\u001b[A\n",
      " 66%|██████▋   | 274602/414113 [01:04<00:32, 4353.11it/s]\u001b[A\n",
      " 66%|██████▋   | 275038/414113 [01:04<00:32, 4318.28it/s]\u001b[A\n",
      " 67%|██████▋   | 275474/414113 [01:04<00:32, 4330.09it/s]\u001b[A\n",
      " 67%|██████▋   | 275913/414113 [01:04<00:31, 4346.36it/s]\u001b[A\n",
      " 67%|██████▋   | 276348/414113 [01:04<00:33, 4075.58it/s]\u001b[A\n",
      " 67%|██████▋   | 276787/414113 [01:04<00:32, 4163.29it/s]\u001b[A\n",
      " 67%|██████▋   | 277211/414113 [01:04<00:32, 4185.12it/s]\u001b[A\n",
      " 67%|██████▋   | 277643/414113 [01:04<00:32, 4222.37it/s]\u001b[A\n",
      " 67%|██████▋   | 278081/414113 [01:04<00:31, 4268.21it/s]\u001b[A\n",
      " 67%|██████▋   | 278510/414113 [01:04<00:31, 4268.88it/s]\u001b[A\n",
      " 67%|██████▋   | 278956/414113 [01:05<00:31, 4322.38it/s]\u001b[A\n",
      " 67%|██████▋   | 279390/414113 [01:05<00:31, 4326.19it/s]\u001b[A\n",
      " 68%|██████▊   | 279824/414113 [01:05<00:31, 4312.47it/s]\u001b[A\n",
      " 68%|██████▊   | 280269/414113 [01:05<00:30, 4350.02it/s]\u001b[A\n",
      " 68%|██████▊   | 280710/414113 [01:05<00:30, 4366.99it/s]\u001b[A\n",
      " 68%|██████▊   | 281147/414113 [01:05<00:30, 4352.44it/s]\u001b[A\n",
      " 68%|██████▊   | 281583/414113 [01:05<00:30, 4344.91it/s]\u001b[A\n",
      " 68%|██████▊   | 282018/414113 [01:05<00:30, 4343.24it/s]\u001b[A\n",
      " 68%|██████▊   | 282454/414113 [01:05<00:30, 4348.05it/s]\u001b[A\n",
      " 68%|██████▊   | 282889/414113 [01:05<00:30, 4342.52it/s]\u001b[A\n",
      " 68%|██████▊   | 283336/414113 [01:06<00:29, 4379.09it/s]\u001b[A\n",
      " 69%|██████▊   | 283781/414113 [01:06<00:29, 4398.17it/s]\u001b[A\n",
      " 69%|██████▊   | 284228/414113 [01:06<00:29, 4416.93it/s]\u001b[A\n",
      " 69%|██████▊   | 284676/414113 [01:06<00:29, 4431.37it/s]\u001b[A\n",
      " 69%|██████▉   | 285120/414113 [01:06<00:29, 4421.47it/s]\u001b[A\n",
      " 69%|██████▉   | 285563/414113 [01:06<00:29, 4379.58it/s]\u001b[A\n",
      " 69%|██████▉   | 286010/414113 [01:06<00:29, 4403.33it/s]\u001b[A\n",
      " 69%|██████▉   | 286451/414113 [01:06<00:29, 4380.72it/s]\u001b[A\n",
      " 69%|██████▉   | 286890/414113 [01:06<00:29, 4366.83it/s]\u001b[A\n",
      " 69%|██████▉   | 287333/414113 [01:06<00:28, 4383.06it/s]\u001b[A\n",
      " 69%|██████▉   | 287773/414113 [01:07<00:28, 4387.78it/s]\u001b[A\n",
      " 70%|██████▉   | 288212/414113 [01:07<00:28, 4375.58it/s]\u001b[A\n",
      " 70%|██████▉   | 288653/414113 [01:07<00:28, 4384.79it/s]\u001b[A\n",
      " 70%|██████▉   | 289092/414113 [01:07<00:28, 4367.36it/s]\u001b[A\n",
      " 70%|██████▉   | 289529/414113 [01:07<00:28, 4361.37it/s]\u001b[A\n",
      " 70%|███████   | 289968/414113 [01:07<00:28, 4367.25it/s]\u001b[A\n",
      " 70%|███████   | 290412/414113 [01:07<00:28, 4388.80it/s]\u001b[A\n",
      " 70%|███████   | 290854/414113 [01:07<00:28, 4397.59it/s]\u001b[A\n",
      " 70%|███████   | 291294/414113 [01:07<00:29, 4132.65it/s]\u001b[A\n",
      " 70%|███████   | 291735/414113 [01:08<00:29, 4211.57it/s]\u001b[A\n",
      " 71%|███████   | 292182/414113 [01:08<00:28, 4283.97it/s]\u001b[A\n",
      " 71%|███████   | 292626/414113 [01:08<00:28, 4329.47it/s]\u001b[A\n",
      " 71%|███████   | 293070/414113 [01:08<00:27, 4360.86it/s]\u001b[A\n",
      " 71%|███████   | 293512/414113 [01:08<00:27, 4376.13it/s]\u001b[A\n",
      " 71%|███████   | 293959/414113 [01:08<00:27, 4402.64it/s]\u001b[A\n",
      " 71%|███████   | 294403/414113 [01:08<00:27, 4412.53it/s]\u001b[A\n",
      " 71%|███████   | 294845/414113 [01:08<00:27, 4348.19it/s]\u001b[A\n",
      " 71%|███████▏  | 295281/414113 [01:08<00:27, 4349.59it/s]\u001b[A\n",
      " 71%|███████▏  | 295718/414113 [01:08<00:27, 4353.71it/s]\u001b[A\n",
      " 72%|███████▏  | 296154/414113 [01:09<00:27, 4287.33it/s]\u001b[A\n",
      " 72%|███████▏  | 296588/414113 [01:09<00:27, 4302.00it/s]\u001b[A\n",
      " 72%|███████▏  | 297020/414113 [01:09<00:27, 4304.99it/s]\u001b[A\n",
      " 72%|███████▏  | 297451/414113 [01:09<00:27, 4270.74it/s]\u001b[A\n",
      " 72%|███████▏  | 297881/414113 [01:09<00:27, 4278.71it/s]\u001b[A\n",
      " 72%|███████▏  | 298310/414113 [01:09<00:27, 4280.77it/s]\u001b[A\n",
      " 72%|███████▏  | 298746/414113 [01:09<00:26, 4302.99it/s]\u001b[A\n",
      " 72%|███████▏  | 299183/414113 [01:09<00:26, 4322.67it/s]\u001b[A\n",
      " 72%|███████▏  | 299616/414113 [01:09<00:26, 4296.26it/s]\u001b[A\n",
      " 72%|███████▏  | 300046/414113 [01:10<00:48, 2365.07it/s]\u001b[A\n",
      " 73%|███████▎  | 300492/414113 [01:10<00:41, 2752.21it/s]\u001b[A\n",
      " 73%|███████▎  | 300924/414113 [01:10<00:36, 3087.77it/s]\u001b[A\n",
      " 73%|███████▎  | 301355/414113 [01:10<00:33, 3374.76it/s]\u001b[A\n",
      " 73%|███████▎  | 301776/414113 [01:10<00:31, 3586.90it/s]\u001b[A\n",
      " 73%|███████▎  | 302222/414113 [01:10<00:29, 3810.23it/s]\u001b[A\n",
      " 73%|███████▎  | 302650/414113 [01:10<00:28, 3939.96it/s]\u001b[A\n",
      " 73%|███████▎  | 303094/414113 [01:10<00:27, 4076.65it/s]\u001b[A\n",
      " 73%|███████▎  | 303527/414113 [01:10<00:26, 4148.32it/s]\u001b[A\n",
      " 73%|███████▎  | 303957/414113 [01:11<00:26, 4187.12it/s]\u001b[A\n",
      " 74%|███████▎  | 304399/414113 [01:11<00:25, 4253.40it/s]\u001b[A\n",
      " 74%|███████▎  | 304839/414113 [01:11<00:25, 4293.27it/s]\u001b[A\n",
      " 74%|███████▎  | 305274/414113 [01:11<00:25, 4289.51it/s]\u001b[A\n",
      " 74%|███████▍  | 305707/414113 [01:11<00:25, 4300.94it/s]\u001b[A\n",
      " 74%|███████▍  | 306144/414113 [01:11<00:24, 4320.52it/s]\u001b[A\n",
      " 74%|███████▍  | 306581/414113 [01:11<00:24, 4335.02it/s]\u001b[A\n",
      " 74%|███████▍  | 307016/414113 [01:11<00:24, 4316.06it/s]\u001b[A\n",
      " 74%|███████▍  | 307449/414113 [01:11<00:24, 4299.90it/s]\u001b[A\n",
      " 74%|███████▍  | 307886/414113 [01:11<00:24, 4318.26it/s]\u001b[A\n",
      " 74%|███████▍  | 308334/414113 [01:12<00:24, 4363.79it/s]\u001b[A\n",
      " 75%|███████▍  | 308776/414113 [01:12<00:24, 4377.81it/s]\u001b[A\n",
      " 75%|███████▍  | 309225/414113 [01:12<00:23, 4410.65it/s]\u001b[A\n",
      " 75%|███████▍  | 309674/414113 [01:12<00:23, 4432.21it/s]\u001b[A\n",
      " 75%|███████▍  | 310118/414113 [01:12<00:23, 4425.40it/s]\u001b[A\n",
      " 75%|███████▍  | 310571/414113 [01:12<00:23, 4453.34it/s]\u001b[A\n",
      " 75%|███████▌  | 311017/414113 [01:12<00:23, 4454.34it/s]\u001b[A\n",
      " 75%|███████▌  | 311463/414113 [01:12<00:23, 4406.51it/s]\u001b[A\n",
      " 75%|███████▌  | 311906/414113 [01:12<00:23, 4413.11it/s]\u001b[A\n",
      " 75%|███████▌  | 312355/414113 [01:13<00:22, 4435.01it/s]\u001b[A\n",
      " 76%|███████▌  | 312799/414113 [01:13<00:22, 4407.77it/s]\u001b[A\n",
      " 76%|███████▌  | 313240/414113 [01:13<00:22, 4406.94it/s]\u001b[A\n",
      " 76%|███████▌  | 313687/414113 [01:13<00:22, 4422.59it/s]\u001b[A\n",
      " 76%|███████▌  | 314136/414113 [01:13<00:22, 4441.39it/s]\u001b[A\n",
      " 76%|███████▌  | 314581/414113 [01:13<00:22, 4439.48it/s]\u001b[A\n",
      " 76%|███████▌  | 315025/414113 [01:13<00:22, 4419.06it/s]\u001b[A\n",
      " 76%|███████▌  | 315471/414113 [01:13<00:22, 4430.93it/s]\u001b[A\n",
      " 76%|███████▋  | 315915/414113 [01:13<00:22, 4428.69it/s]\u001b[A\n",
      " 76%|███████▋  | 316368/414113 [01:13<00:21, 4458.07it/s]\u001b[A\n",
      " 77%|███████▋  | 316814/414113 [01:14<00:21, 4433.10it/s]\u001b[A\n",
      " 77%|███████▋  | 317258/414113 [01:14<00:21, 4429.59it/s]\u001b[A\n",
      " 77%|███████▋  | 317702/414113 [01:14<00:21, 4427.79it/s]\u001b[A\n",
      " 77%|███████▋  | 318145/414113 [01:14<00:21, 4425.54it/s]\u001b[A\n",
      " 77%|███████▋  | 318598/414113 [01:14<00:21, 4455.89it/s]\u001b[A\n",
      " 77%|███████▋  | 319049/414113 [01:14<00:21, 4470.02it/s]\u001b[A\n",
      " 77%|███████▋  | 319497/414113 [01:14<00:21, 4389.92it/s]\u001b[A\n",
      " 77%|███████▋  | 319950/414113 [01:14<00:21, 4428.26it/s]\u001b[A\n",
      " 77%|███████▋  | 320394/414113 [01:14<00:21, 4431.05it/s]\u001b[A\n",
      " 77%|███████▋  | 320849/414113 [01:14<00:20, 4464.48it/s]\u001b[A\n",
      " 78%|███████▊  | 321296/414113 [01:15<00:20, 4427.23it/s]\u001b[A\n",
      " 78%|███████▊  | 321745/414113 [01:15<00:20, 4445.75it/s]\u001b[A\n",
      " 78%|███████▊  | 322192/414113 [01:15<00:20, 4452.00it/s]\u001b[A\n",
      " 78%|███████▊  | 322638/414113 [01:15<00:20, 4428.74it/s]\u001b[A\n",
      " 78%|███████▊  | 323086/414113 [01:15<00:20, 4441.75it/s]\u001b[A\n",
      " 78%|███████▊  | 323541/414113 [01:15<00:20, 4472.03it/s]\u001b[A\n",
      " 78%|███████▊  | 323989/414113 [01:15<00:20, 4466.38it/s]\u001b[A\n",
      " 78%|███████▊  | 324436/414113 [01:15<00:20, 4449.71it/s]\u001b[A\n",
      " 78%|███████▊  | 324884/414113 [01:15<00:20, 4458.25it/s]\u001b[A\n",
      " 79%|███████▊  | 325330/414113 [01:15<00:20, 4261.45it/s]\u001b[A\n",
      " 79%|███████▊  | 325779/414113 [01:16<00:20, 4325.38it/s]\u001b[A\n",
      " 79%|███████▉  | 326215/414113 [01:16<00:20, 4335.21it/s]\u001b[A\n",
      " 79%|███████▉  | 326658/414113 [01:16<00:20, 4362.92it/s]\u001b[A\n",
      " 79%|███████▉  | 327096/414113 [01:16<00:20, 4333.99it/s]\u001b[A\n",
      " 79%|███████▉  | 327546/414113 [01:16<00:19, 4380.16it/s]\u001b[A\n",
      " 79%|███████▉  | 327985/414113 [01:16<00:19, 4361.74it/s]\u001b[A\n",
      " 79%|███████▉  | 328423/414113 [01:16<00:19, 4365.60it/s]\u001b[A\n",
      " 79%|███████▉  | 328860/414113 [01:16<00:19, 4337.31it/s]\u001b[A\n",
      " 80%|███████▉  | 329294/414113 [01:16<00:19, 4326.78it/s]\u001b[A\n",
      " 80%|███████▉  | 329733/414113 [01:16<00:19, 4344.36it/s]\u001b[A\n",
      " 80%|███████▉  | 330168/414113 [01:17<00:19, 4332.07it/s]\u001b[A\n",
      " 80%|███████▉  | 330602/414113 [01:17<00:19, 4291.26it/s]\u001b[A\n",
      " 80%|███████▉  | 331032/414113 [01:17<00:19, 4245.02it/s]\u001b[A\n",
      " 80%|████████  | 331458/414113 [01:17<00:19, 4248.42it/s]\u001b[A\n",
      " 80%|████████  | 331884/414113 [01:17<00:19, 4247.02it/s]\u001b[A\n",
      " 80%|████████  | 332326/414113 [01:17<00:19, 4297.35it/s]\u001b[A\n",
      " 80%|████████  | 332769/414113 [01:17<00:18, 4335.98it/s]\u001b[A\n",
      " 80%|████████  | 333203/414113 [01:17<00:18, 4318.62it/s]\u001b[A\n",
      " 81%|████████  | 333636/414113 [01:17<00:18, 4293.50it/s]\u001b[A\n",
      " 81%|████████  | 334066/414113 [01:17<00:18, 4291.48it/s]\u001b[A\n",
      " 81%|████████  | 334501/414113 [01:18<00:18, 4307.36it/s]\u001b[A\n",
      " 81%|████████  | 334932/414113 [01:18<00:18, 4285.86it/s]\u001b[A\n",
      " 81%|████████  | 335366/414113 [01:18<00:18, 4300.02it/s]\u001b[A\n",
      " 81%|████████  | 335797/414113 [01:18<00:18, 4291.84it/s]\u001b[A\n",
      " 81%|████████  | 336227/414113 [01:18<00:18, 4238.37it/s]\u001b[A\n",
      " 81%|████████▏ | 336652/414113 [01:18<00:18, 4226.15it/s]\u001b[A\n",
      " 81%|████████▏ | 337077/414113 [01:18<00:18, 4230.77it/s]\u001b[A\n",
      " 81%|████████▏ | 337501/414113 [01:18<00:18, 4230.65it/s]\u001b[A\n",
      " 82%|████████▏ | 337925/414113 [01:18<00:18, 4214.57it/s]\u001b[A\n",
      " 82%|████████▏ | 338347/414113 [01:18<00:18, 4173.95it/s]\u001b[A\n",
      " 82%|████████▏ | 338765/414113 [01:19<00:18, 3985.24it/s]\u001b[A\n",
      " 82%|████████▏ | 339185/414113 [01:19<00:18, 4047.26it/s]\u001b[A\n",
      " 82%|████████▏ | 339611/414113 [01:19<00:18, 4106.55it/s]\u001b[A\n",
      " 82%|████████▏ | 340041/414113 [01:19<00:17, 4161.83it/s]\u001b[A\n",
      " 82%|████████▏ | 340476/414113 [01:19<00:17, 4214.45it/s]\u001b[A\n",
      " 82%|████████▏ | 340899/414113 [01:19<00:17, 4214.94it/s]\u001b[A\n",
      " 82%|████████▏ | 341332/414113 [01:19<00:17, 4246.54it/s]\u001b[A\n",
      " 83%|████████▎ | 341758/414113 [01:19<00:17, 4249.26it/s]\u001b[A\n",
      " 83%|████████▎ | 342187/414113 [01:19<00:16, 4259.83it/s]\u001b[A\n",
      " 83%|████████▎ | 342614/414113 [01:19<00:16, 4247.53it/s]\u001b[A\n",
      " 83%|████████▎ | 343050/414113 [01:20<00:16, 4280.37it/s]\u001b[A\n",
      " 83%|████████▎ | 343479/414113 [01:20<00:16, 4271.07it/s]\u001b[A\n",
      " 83%|████████▎ | 343907/414113 [01:20<00:16, 4273.13it/s]\u001b[A\n",
      " 83%|████████▎ | 344338/414113 [01:20<00:16, 4281.24it/s]\u001b[A\n",
      " 83%|████████▎ | 344775/414113 [01:20<00:16, 4304.34it/s]\u001b[A\n",
      " 83%|████████▎ | 345206/414113 [01:20<00:16, 4281.41it/s]\u001b[A\n",
      " 83%|████████▎ | 345642/414113 [01:20<00:15, 4304.51it/s]\u001b[A\n",
      " 84%|████████▎ | 346073/414113 [01:20<00:15, 4305.28it/s]\u001b[A\n",
      " 84%|████████▎ | 346504/414113 [01:20<00:15, 4302.95it/s]\u001b[A\n",
      " 84%|████████▍ | 346935/414113 [01:21<00:15, 4281.27it/s]\u001b[A\n",
      " 84%|████████▍ | 347364/414113 [01:21<00:15, 4276.14it/s]\u001b[A\n",
      " 84%|████████▍ | 347793/414113 [01:21<00:15, 4279.72it/s]\u001b[A\n",
      " 84%|████████▍ | 348222/414113 [01:21<00:15, 4274.88it/s]\u001b[A\n",
      " 84%|████████▍ | 348652/414113 [01:21<00:15, 4280.83it/s]\u001b[A\n",
      " 84%|████████▍ | 349088/414113 [01:21<00:15, 4303.57it/s]\u001b[A\n",
      " 84%|████████▍ | 349519/414113 [01:21<00:15, 4293.06it/s]\u001b[A\n",
      " 85%|████████▍ | 349949/414113 [01:21<00:14, 4293.89it/s]\u001b[A\n",
      " 85%|████████▍ | 350385/414113 [01:21<00:14, 4312.27it/s]\u001b[A\n",
      " 85%|████████▍ | 350827/414113 [01:21<00:14, 4343.06it/s]\u001b[A\n",
      " 85%|████████▍ | 351270/414113 [01:22<00:14, 4367.60it/s]\u001b[A\n",
      " 85%|████████▍ | 351707/414113 [01:22<00:14, 4348.95it/s]\u001b[A\n",
      " 85%|████████▌ | 352142/414113 [01:22<00:14, 4320.15it/s]\u001b[A\n",
      " 85%|████████▌ | 352578/414113 [01:22<00:14, 4331.42it/s]\u001b[A\n",
      " 85%|████████▌ | 353012/414113 [01:22<00:14, 4321.89it/s]\u001b[A\n",
      " 85%|████████▌ | 353449/414113 [01:22<00:13, 4335.73it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 353886/414113 [01:22<00:13, 4343.36it/s]\u001b[A\n",
      " 86%|████████▌ | 354321/414113 [01:22<00:13, 4334.21it/s]\u001b[A\n",
      " 86%|████████▌ | 354755/414113 [01:22<00:13, 4313.62it/s]\u001b[A\n",
      " 86%|████████▌ | 355198/414113 [01:22<00:13, 4347.03it/s]\u001b[A\n",
      " 86%|████████▌ | 355644/414113 [01:23<00:13, 4377.41it/s]\u001b[A\n",
      " 86%|████████▌ | 356082/414113 [01:23<00:13, 4364.27it/s]\u001b[A\n",
      " 86%|████████▌ | 356519/414113 [01:23<00:13, 4354.25it/s]\u001b[A\n",
      " 86%|████████▌ | 356957/414113 [01:23<00:13, 4359.67it/s]\u001b[A\n",
      " 86%|████████▋ | 357394/414113 [01:23<00:13, 4355.17it/s]\u001b[A\n",
      " 86%|████████▋ | 357832/414113 [01:23<00:12, 4360.87it/s]\u001b[A\n",
      " 87%|████████▋ | 358269/414113 [01:23<00:12, 4326.52it/s]\u001b[A\n",
      " 87%|████████▋ | 358714/414113 [01:23<00:12, 4361.67it/s]\u001b[A\n",
      " 87%|████████▋ | 359155/414113 [01:23<00:12, 4372.73it/s]\u001b[A\n",
      " 87%|████████▋ | 359595/414113 [01:23<00:12, 4379.23it/s]\u001b[A\n",
      " 87%|████████▋ | 360041/414113 [01:24<00:12, 4400.73it/s]\u001b[A\n",
      " 87%|████████▋ | 360482/414113 [01:24<00:12, 4379.40it/s]\u001b[A\n",
      " 87%|████████▋ | 360921/414113 [01:24<00:12, 4375.45it/s]\u001b[A\n",
      " 87%|████████▋ | 361362/414113 [01:24<00:12, 4384.70it/s]\u001b[A\n",
      " 87%|████████▋ | 361807/414113 [01:24<00:11, 4401.85it/s]\u001b[A\n",
      " 87%|████████▋ | 362248/414113 [01:24<00:11, 4371.06it/s]\u001b[A\n",
      " 88%|████████▊ | 362686/414113 [01:24<00:11, 4355.80it/s]\u001b[A\n",
      " 88%|████████▊ | 363122/414113 [01:24<00:11, 4327.76it/s]\u001b[A\n",
      " 88%|████████▊ | 363555/414113 [01:24<00:11, 4247.69it/s]\u001b[A\n",
      " 88%|████████▊ | 363981/414113 [01:24<00:12, 4040.97it/s]\u001b[A\n",
      " 88%|████████▊ | 364420/414113 [01:25<00:12, 4139.43it/s]\u001b[A\n",
      " 88%|████████▊ | 364837/414113 [01:25<00:11, 4146.01it/s]\u001b[A\n",
      " 88%|████████▊ | 365277/414113 [01:25<00:11, 4217.07it/s]\u001b[A\n",
      " 88%|████████▊ | 365717/414113 [01:25<00:11, 4268.63it/s]\u001b[A\n",
      " 88%|████████▊ | 366153/414113 [01:25<00:11, 4293.85it/s]\u001b[A\n",
      " 89%|████████▊ | 366584/414113 [01:25<00:11, 4233.95it/s]\u001b[A\n",
      " 89%|████████▊ | 367009/414113 [01:25<00:11, 4183.92it/s]\u001b[A\n",
      " 89%|████████▊ | 367442/414113 [01:25<00:11, 4225.36it/s]\u001b[A\n",
      " 89%|████████▉ | 367870/414113 [01:25<00:10, 4240.29it/s]\u001b[A\n",
      " 89%|████████▉ | 368299/414113 [01:25<00:10, 4253.63it/s]\u001b[A\n",
      " 89%|████████▉ | 368748/414113 [01:26<00:10, 4320.54it/s]\u001b[A\n",
      " 89%|████████▉ | 369195/414113 [01:26<00:10, 4363.62it/s]\u001b[A\n",
      " 89%|████████▉ | 369632/414113 [01:26<00:10, 4337.82it/s]\u001b[A\n",
      " 89%|████████▉ | 370067/414113 [01:26<00:10, 4331.66it/s]\u001b[A\n",
      " 89%|████████▉ | 370501/414113 [01:26<00:10, 4321.20it/s]\u001b[A\n",
      " 90%|████████▉ | 370934/414113 [01:26<00:09, 4322.08it/s]\u001b[A\n",
      " 90%|████████▉ | 371367/414113 [01:26<00:09, 4304.25it/s]\u001b[A\n",
      " 90%|████████▉ | 371798/414113 [01:26<00:09, 4285.18it/s]\u001b[A\n",
      " 90%|████████▉ | 372228/414113 [01:26<00:09, 4288.07it/s]\u001b[A\n",
      " 90%|████████▉ | 372659/414113 [01:26<00:09, 4293.63it/s]\u001b[A\n",
      " 90%|█████████ | 373091/414113 [01:27<00:09, 4300.77it/s]\u001b[A\n",
      " 90%|█████████ | 373523/414113 [01:27<00:09, 4304.52it/s]\u001b[A\n",
      " 90%|█████████ | 373957/414113 [01:27<00:09, 4313.46it/s]\u001b[A\n",
      " 90%|█████████ | 374399/414113 [01:27<00:09, 4342.97it/s]\u001b[A\n",
      " 91%|█████████ | 374834/414113 [01:27<00:09, 4337.41it/s]\u001b[A\n",
      " 91%|█████████ | 375268/414113 [01:27<00:08, 4326.27it/s]\u001b[A\n",
      " 91%|█████████ | 375701/414113 [01:27<00:08, 4310.19it/s]\u001b[A\n",
      " 91%|█████████ | 376140/414113 [01:27<00:08, 4330.14it/s]\u001b[A\n",
      " 91%|█████████ | 376574/414113 [01:27<00:08, 4332.73it/s]\u001b[A\n",
      " 91%|█████████ | 377008/414113 [01:27<00:08, 4308.53it/s]\u001b[A\n",
      " 91%|█████████ | 377445/414113 [01:28<00:08, 4323.37it/s]\u001b[A\n",
      " 91%|█████████▏| 377884/414113 [01:28<00:08, 4340.40it/s]\u001b[A\n",
      " 91%|█████████▏| 378325/414113 [01:28<00:08, 4360.55it/s]\u001b[A\n",
      " 91%|█████████▏| 378766/414113 [01:28<00:08, 4375.17it/s]\u001b[A\n",
      " 92%|█████████▏| 379204/414113 [01:28<00:07, 4373.58it/s]\u001b[A\n",
      " 92%|█████████▏| 379642/414113 [01:28<00:07, 4344.87it/s]\u001b[A\n",
      " 92%|█████████▏| 380077/414113 [01:28<00:07, 4319.59it/s]\u001b[A\n",
      " 92%|█████████▏| 380510/414113 [01:28<00:07, 4270.47it/s]\u001b[A\n",
      " 92%|█████████▏| 380945/414113 [01:28<00:07, 4292.19it/s]\u001b[A\n",
      " 92%|█████████▏| 381387/414113 [01:28<00:07, 4326.96it/s]\u001b[A\n",
      " 92%|█████████▏| 381822/414113 [01:29<00:07, 4331.17it/s]\u001b[A\n",
      " 92%|█████████▏| 382256/414113 [01:29<00:07, 4331.94it/s]\u001b[A\n",
      " 92%|█████████▏| 382694/414113 [01:29<00:07, 4344.15it/s]\u001b[A\n",
      " 93%|█████████▎| 383129/414113 [01:29<00:07, 4312.93it/s]\u001b[A\n",
      " 93%|█████████▎| 383565/414113 [01:29<00:07, 4326.80it/s]\u001b[A\n",
      " 93%|█████████▎| 383998/414113 [01:29<00:07, 4266.30it/s]\u001b[A\n",
      " 93%|█████████▎| 384425/414113 [01:29<00:06, 4259.99it/s]\u001b[A\n",
      " 93%|█████████▎| 384852/414113 [01:29<00:06, 4255.29it/s]\u001b[A\n",
      " 93%|█████████▎| 385287/414113 [01:29<00:06, 4282.51it/s]\u001b[A\n",
      " 93%|█████████▎| 385732/414113 [01:29<00:06, 4330.64it/s]\u001b[A\n",
      " 93%|█████████▎| 386166/414113 [01:30<00:06, 4301.82it/s]\u001b[A\n",
      " 93%|█████████▎| 386597/414113 [01:30<00:06, 4299.26it/s]\u001b[A\n",
      " 93%|█████████▎| 387038/414113 [01:30<00:06, 4329.68it/s]\u001b[A\n",
      " 94%|█████████▎| 387472/414113 [01:30<00:06, 4328.80it/s]\u001b[A\n",
      " 94%|█████████▎| 387910/414113 [01:30<00:06, 4343.16it/s]\u001b[A\n",
      " 94%|█████████▍| 388350/414113 [01:30<00:05, 4358.54it/s]\u001b[A\n",
      " 94%|█████████▍| 388786/414113 [01:30<00:05, 4342.82it/s]\u001b[A\n",
      " 94%|█████████▍| 389221/414113 [01:30<00:05, 4332.87it/s]\u001b[A\n",
      " 94%|█████████▍| 389655/414113 [01:30<00:05, 4281.84it/s]\u001b[A\n",
      " 94%|█████████▍| 390084/414113 [01:31<00:05, 4274.97it/s]\u001b[A\n",
      " 94%|█████████▍| 390512/414113 [01:31<00:05, 4268.85it/s]\u001b[A\n",
      " 94%|█████████▍| 390939/414113 [01:31<00:05, 4260.19it/s]\u001b[A\n",
      " 95%|█████████▍| 391381/414113 [01:31<00:05, 4304.87it/s]\u001b[A\n",
      " 95%|█████████▍| 391827/414113 [01:31<00:05, 4349.73it/s]\u001b[A\n",
      " 95%|█████████▍| 392268/414113 [01:31<00:05, 4365.39it/s]\u001b[A\n",
      " 95%|█████████▍| 392705/414113 [01:31<00:04, 4350.01it/s]\u001b[A\n",
      " 95%|█████████▍| 393141/414113 [01:31<00:04, 4257.25it/s]\u001b[A\n",
      " 95%|█████████▌| 393569/414113 [01:31<00:04, 4263.42it/s]\u001b[A\n",
      " 95%|█████████▌| 394003/414113 [01:31<00:04, 4282.98it/s]\u001b[A\n",
      " 95%|█████████▌| 394432/414113 [01:32<00:04, 4284.08it/s]\u001b[A\n",
      " 95%|█████████▌| 394861/414113 [01:32<00:04, 4265.44it/s]\u001b[A\n",
      " 95%|█████████▌| 395288/414113 [01:32<00:04, 4241.41it/s]\u001b[A\n",
      " 96%|█████████▌| 395716/414113 [01:32<00:04, 4250.48it/s]\u001b[A\n",
      " 96%|█████████▌| 396142/414113 [01:32<00:04, 4250.38it/s]\u001b[A\n",
      " 96%|█████████▌| 396579/414113 [01:32<00:04, 4283.34it/s]\u001b[A\n",
      " 96%|█████████▌| 397008/414113 [01:32<00:03, 4284.05it/s]\u001b[A\n",
      " 96%|█████████▌| 397445/414113 [01:32<00:03, 4306.17it/s]\u001b[A\n",
      " 96%|█████████▌| 397876/414113 [01:32<00:03, 4264.81it/s]\u001b[A\n",
      " 96%|█████████▌| 398320/414113 [01:32<00:03, 4313.54it/s]\u001b[A\n",
      " 96%|█████████▋| 398754/414113 [01:33<00:03, 4319.07it/s]\u001b[A\n",
      " 96%|█████████▋| 399188/414113 [01:33<00:03, 4322.75it/s]\u001b[A\n",
      " 97%|█████████▋| 399621/414113 [01:33<00:03, 4167.64it/s]\u001b[A\n",
      " 97%|█████████▋| 400044/414113 [01:33<00:03, 4184.71it/s]\u001b[A\n",
      " 97%|█████████▋| 400481/414113 [01:33<00:03, 4237.35it/s]\u001b[A\n",
      " 97%|█████████▋| 400912/414113 [01:33<00:03, 4257.83it/s]\u001b[A\n",
      " 97%|█████████▋| 401353/414113 [01:33<00:02, 4299.77it/s]\u001b[A\n",
      " 97%|█████████▋| 401794/414113 [01:33<00:02, 4331.02it/s]\u001b[A\n",
      " 97%|█████████▋| 402228/414113 [01:33<00:02, 4265.30it/s]\u001b[A\n",
      " 97%|█████████▋| 402670/414113 [01:33<00:02, 4310.16it/s]\u001b[A\n",
      " 97%|█████████▋| 403105/414113 [01:34<00:02, 4319.59it/s]\u001b[A\n",
      " 97%|█████████▋| 403538/414113 [01:34<00:02, 4261.99it/s]\u001b[A\n",
      " 98%|█████████▊| 403965/414113 [01:34<00:02, 4248.24it/s]\u001b[A\n",
      " 98%|█████████▊| 404403/414113 [01:34<00:02, 4286.91it/s]\u001b[A\n",
      " 98%|█████████▊| 404838/414113 [01:34<00:02, 4303.56it/s]\u001b[A\n",
      " 98%|█████████▊| 405269/414113 [01:34<00:02, 4302.85it/s]\u001b[A\n",
      " 98%|█████████▊| 405705/414113 [01:34<00:01, 4318.08it/s]\u001b[A\n",
      " 98%|█████████▊| 406137/414113 [01:34<00:01, 4304.69it/s]\u001b[A\n",
      " 98%|█████████▊| 406574/414113 [01:34<00:01, 4323.84it/s]\u001b[A\n",
      " 98%|█████████▊| 407026/414113 [01:34<00:01, 4378.78it/s]\u001b[A\n",
      " 98%|█████████▊| 407468/414113 [01:35<00:01, 4390.69it/s]\u001b[A\n",
      " 99%|█████████▊| 407908/414113 [01:35<00:01, 4362.42it/s]\u001b[A\n",
      " 99%|█████████▊| 408345/414113 [01:35<00:01, 4327.68it/s]\u001b[A\n",
      " 99%|█████████▊| 408778/414113 [01:35<00:01, 4328.34it/s]\u001b[A\n",
      " 99%|█████████▉| 409214/414113 [01:35<00:01, 4335.13it/s]\u001b[A\n",
      " 99%|█████████▉| 409648/414113 [01:35<00:01, 4332.21it/s]\u001b[A\n",
      " 99%|█████████▉| 410085/414113 [01:35<00:00, 4341.81it/s]\u001b[A\n",
      " 99%|█████████▉| 410520/414113 [01:35<00:00, 4343.05it/s]\u001b[A\n",
      " 99%|█████████▉| 410955/414113 [01:35<00:00, 4317.43it/s]\u001b[A\n",
      " 99%|█████████▉| 411406/414113 [01:35<00:00, 4371.10it/s]\u001b[A\n",
      " 99%|█████████▉| 411844/414113 [01:36<00:00, 4368.12it/s]\u001b[A\n",
      "100%|█████████▉| 412281/414113 [01:36<00:00, 4322.48it/s]\u001b[A\n",
      "100%|█████████▉| 412726/414113 [01:36<00:00, 4357.45it/s]\u001b[A\n",
      "100%|█████████▉| 413177/414113 [01:36<00:00, 4400.47it/s]\u001b[A\n",
      "100%|█████████▉| 413618/414113 [01:36<00:00, 4399.11it/s]\u001b[A\n",
      "100%|█████████▉| 414059/414113 [01:36<00:00, 4339.43it/s]\u001b[A\n",
      "100%|██████████| 414113/414113 [01:36<00:00, 4287.70it/s]\u001b[ADownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/resnet50-19c8e357.pth\n",
      "\n",
      "  0%|          | 0/102502400 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 393216/102502400 [00:00<00:26, 3904756.07it/s]\u001b[A\n",
      "  5%|▍         | 4792320/102502400 [00:00<00:18, 5372741.82it/s]\u001b[A\n",
      "  8%|▊         | 8552448/102502400 [00:00<00:13, 7225575.67it/s]\u001b[A\n",
      " 12%|█▏        | 12091392/102502400 [00:00<00:09, 9362424.69it/s]\u001b[A\n",
      " 18%|█▊        | 18776064/102502400 [00:00<00:06, 12338328.01it/s]\u001b[A\n",
      " 21%|██▏       | 21921792/102502400 [00:00<00:05, 15086462.88it/s]\u001b[A\n",
      " 27%|██▋       | 27295744/102502400 [00:00<00:04, 17295962.87it/s]\u001b[A\n",
      " 30%|██▉       | 30261248/102502400 [00:01<00:06, 11995522.55it/s]\u001b[A\n",
      " 32%|███▏      | 33120256/102502400 [00:01<00:04, 14523885.34it/s]\u001b[A\n",
      " 35%|███▍      | 35577856/102502400 [00:01<00:04, 16491473.12it/s]\u001b[A\n",
      " 37%|███▋      | 38027264/102502400 [00:01<00:04, 15414921.75it/s]\u001b[A\n",
      " 39%|███▉      | 40468480/102502400 [00:01<00:04, 14571811.99it/s]\u001b[A\n",
      " 41%|████▏     | 42336256/102502400 [00:02<00:04, 13331194.52it/s]\u001b[A\n",
      " 43%|████▎     | 43982848/102502400 [00:02<00:04, 13930112.25it/s]\u001b[A\n",
      " 48%|████▊     | 49512448/102502400 [00:02<00:02, 17959942.37it/s]\u001b[A\n",
      " 52%|█████▏    | 53051392/102502400 [00:02<00:02, 21071461.23it/s]\u001b[A\n",
      " 58%|█████▊    | 59670528/102502400 [00:02<00:01, 23822518.55it/s]\u001b[A\n",
      " 61%|██████▏   | 62808064/102502400 [00:02<00:01, 22203764.15it/s]\u001b[A\n",
      " 66%|██████▌   | 67264512/102502400 [00:02<00:01, 26135255.16it/s]\u001b[A\n",
      " 69%|██████▉   | 70541312/102502400 [00:02<00:01, 22011861.12it/s]\u001b[A\n",
      " 73%|███████▎  | 75071488/102502400 [00:03<00:01, 26007351.12it/s]\u001b[A\n",
      " 79%|███████▉  | 80871424/102502400 [00:03<00:00, 31160698.76it/s]\u001b[A\n",
      " 83%|████████▎ | 84918272/102502400 [00:03<00:00, 33018444.85it/s]\u001b[A\n",
      " 88%|████████▊ | 89751552/102502400 [00:03<00:00, 31038331.07it/s]\u001b[A\n",
      " 91%|█████████ | 93364224/102502400 [00:03<00:00, 26496120.01it/s]\u001b[A\n",
      " 94%|█████████▍| 96485376/102502400 [00:03<00:00, 25609140.14it/s]\u001b[A\n",
      " 97%|█████████▋| 99385344/102502400 [00:03<00:00, 21096927.16it/s]\u001b[A\n",
      " 99%|█████████▉| 101908480/102502400 [00:04<00:00, 22186842.81it/s]\u001b[A\n",
      "100%|██████████| 102502400/102502400 [00:04<00:00, 25012383.33it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size = 32          # batch size\n",
    "vocab_threshold = 5        # minimum word count threshold\n",
    "vocab_from_file = True    # if True, load existing vocab file\n",
    "embed_size = 256           # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 3             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(encoder.embed.parameters())+list(decoder.parameters())\n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "optimizer = torch.optim.Adam(params)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Train your Model\n",
    "\n",
    "Once you have executed the code cell in **Step 1**, the training procedure below should run without issue.  \n",
    "\n",
    "It is completely fine to leave the code cell below as-is without modifications to train your model.  However, if you would like to modify the code used to train the model below, you must ensure that your changes are easily parsed by your reviewer.  In other words, make sure to provide appropriate comments to describe how your code works!  \n",
    "\n",
    "You may find it useful to load saved weights to resume training.  In that case, note the names of the files containing the encoder and decoder weights that you'd like to load (`encoder_file` and `decoder_file`).  Then you can load the weights by using the lines below:\n",
    "\n",
    "```python\n",
    "# Load pre-trained weights before resuming training.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "```\n",
    "\n",
    "While trying out parameters, make sure to take extensive notes and record the settings that you used in your various training runs.  In particular, you don't want to encounter a situation where you've trained a model for several hours but can't remember what settings you used :).\n",
    "\n",
    "### A Note on Tuning Hyperparameters\n",
    "\n",
    "To figure out how well your model is doing, you can look at how the training loss and perplexity evolve during training - and for the purposes of this project, you are encouraged to amend the hyperparameters based on this information.  \n",
    "\n",
    "However, this will not tell you if your model is overfitting to the training data, and, unfortunately, overfitting is a problem that is commonly encountered when training image captioning models.  \n",
    "\n",
    "For this project, you need not worry about overfitting. **This project does not have strict requirements regarding the performance of your model**, and you just need to demonstrate that your model has learned **_something_** when you generate captions on the test data.  For now, we strongly encourage you to train your model for the suggested 3 epochs without worrying about performance; then, you should immediately transition to the next notebook in the sequence (**3_Inference.ipynb**) to see how your model performs on the test data.  If your model needs to be changed, you can come back to this notebook, amend hyperparameters (if necessary), and re-train the model.\n",
    "\n",
    "That said, if you would like to go above and beyond in this project, you can read about some approaches to minimizing overfitting in section 4.3.1 of [this paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505636).  In the next (optional) step of this notebook, we provide some guidance for assessing the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/12942], Loss: 3.6893, Perplexity: 40.0180\n",
      "Epoch [1/3], Step [200/12942], Loss: 3.7330, Perplexity: 41.80557\n",
      "Epoch [1/3], Step [300/12942], Loss: 3.3167, Perplexity: 27.5697\n",
      "Epoch [1/3], Step [400/12942], Loss: 3.2483, Perplexity: 25.74726\n",
      "Epoch [1/3], Step [500/12942], Loss: 3.0991, Perplexity: 22.1787\n",
      "Epoch [1/3], Step [600/12942], Loss: 3.1053, Perplexity: 22.3152\n",
      "Epoch [1/3], Step [700/12942], Loss: 2.8849, Perplexity: 17.90185\n",
      "Epoch [1/3], Step [800/12942], Loss: 3.0108, Perplexity: 20.3044\n",
      "Epoch [1/3], Step [900/12942], Loss: 3.1583, Perplexity: 23.5316\n",
      "Epoch [1/3], Step [1000/12942], Loss: 3.1493, Perplexity: 23.3208\n",
      "Epoch [1/3], Step [1100/12942], Loss: 2.9500, Perplexity: 19.1054\n",
      "Epoch [1/3], Step [1200/12942], Loss: 3.1873, Perplexity: 24.2236\n",
      "Epoch [1/3], Step [1300/12942], Loss: 3.1431, Perplexity: 23.1754\n",
      "Epoch [1/3], Step [1400/12942], Loss: 3.1275, Perplexity: 22.8179\n",
      "Epoch [1/3], Step [1500/12942], Loss: 3.4471, Perplexity: 31.4094\n",
      "Epoch [1/3], Step [1600/12942], Loss: 2.6304, Perplexity: 13.8800\n",
      "Epoch [1/3], Step [1700/12942], Loss: 2.6071, Perplexity: 13.5593\n",
      "Epoch [1/3], Step [1800/12942], Loss: 2.7097, Perplexity: 15.0251\n",
      "Epoch [1/3], Step [1900/12942], Loss: 2.8406, Perplexity: 17.1253\n",
      "Epoch [1/3], Step [2000/12942], Loss: 2.5286, Perplexity: 12.5353\n",
      "Epoch [1/3], Step [2100/12942], Loss: 2.2816, Perplexity: 9.79257\n",
      "Epoch [1/3], Step [2400/12942], Loss: 2.5208, Perplexity: 12.4390\n",
      "Epoch [1/3], Step [2500/12942], Loss: 2.4709, Perplexity: 11.8334\n",
      "Epoch [1/3], Step [2600/12942], Loss: 2.5596, Perplexity: 12.9305\n",
      "Epoch [1/3], Step [2700/12942], Loss: 2.3939, Perplexity: 10.9563\n",
      "Epoch [1/3], Step [2800/12942], Loss: 2.6916, Perplexity: 14.7555\n",
      "Epoch [1/3], Step [2900/12942], Loss: 2.3264, Perplexity: 10.2409\n",
      "Epoch [1/3], Step [3000/12942], Loss: 2.5283, Perplexity: 12.5327\n",
      "Epoch [1/3], Step [3100/12942], Loss: 2.1470, Perplexity: 8.55885\n",
      "Epoch [1/3], Step [3200/12942], Loss: 2.3528, Perplexity: 10.5151\n",
      "Epoch [1/3], Step [3300/12942], Loss: 2.8335, Perplexity: 17.0041\n",
      "Epoch [1/3], Step [3400/12942], Loss: 2.5202, Perplexity: 12.43109\n",
      "Epoch [1/3], Step [3500/12942], Loss: 2.3400, Perplexity: 10.3816\n",
      "Epoch [1/3], Step [3600/12942], Loss: 2.4614, Perplexity: 11.7218\n",
      "Epoch [1/3], Step [3700/12942], Loss: 2.4090, Perplexity: 11.1225\n",
      "Epoch [1/3], Step [3800/12942], Loss: 3.0684, Perplexity: 21.5075\n",
      "Epoch [1/3], Step [3900/12942], Loss: 2.1625, Perplexity: 8.69289\n",
      "Epoch [1/3], Step [4000/12942], Loss: 2.1294, Perplexity: 8.40956\n",
      "Epoch [1/3], Step [4100/12942], Loss: 2.5273, Perplexity: 12.5198\n",
      "Epoch [1/3], Step [4200/12942], Loss: 2.7525, Perplexity: 15.6819\n",
      "Epoch [1/3], Step [4300/12942], Loss: 2.7679, Perplexity: 15.9257\n",
      "Epoch [1/3], Step [4400/12942], Loss: 2.8531, Perplexity: 17.3423\n",
      "Epoch [1/3], Step [4500/12942], Loss: 2.4410, Perplexity: 11.4850\n",
      "Epoch [1/3], Step [4600/12942], Loss: 2.1281, Perplexity: 8.39870\n",
      "Epoch [1/3], Step [4700/12942], Loss: 2.3039, Perplexity: 10.0133\n",
      "Epoch [1/3], Step [4800/12942], Loss: 2.5011, Perplexity: 12.1964\n",
      "Epoch [1/3], Step [4900/12942], Loss: 2.1201, Perplexity: 8.33207\n",
      "Epoch [1/3], Step [5000/12942], Loss: 3.2435, Perplexity: 25.6223\n",
      "Epoch [1/3], Step [5100/12942], Loss: 2.8078, Perplexity: 16.5729\n",
      "Epoch [1/3], Step [5200/12942], Loss: 2.3710, Perplexity: 10.7084\n",
      "Epoch [1/3], Step [5300/12942], Loss: 2.6667, Perplexity: 14.3918\n",
      "Epoch [1/3], Step [5400/12942], Loss: 2.4068, Perplexity: 11.0988\n",
      "Epoch [1/3], Step [5500/12942], Loss: 2.2348, Perplexity: 9.34443\n",
      "Epoch [1/3], Step [5600/12942], Loss: 2.3537, Perplexity: 10.5244\n",
      "Epoch [1/3], Step [5700/12942], Loss: 2.7499, Perplexity: 15.6404\n",
      "Epoch [1/3], Step [5800/12942], Loss: 2.1338, Perplexity: 8.44655\n",
      "Epoch [1/3], Step [5900/12942], Loss: 2.2881, Perplexity: 9.85612\n",
      "Epoch [1/3], Step [6000/12942], Loss: 2.3026, Perplexity: 10.0004\n",
      "Epoch [1/3], Step [6100/12942], Loss: 2.5513, Perplexity: 12.8236\n",
      "Epoch [1/3], Step [6200/12942], Loss: 2.2778, Perplexity: 9.75559\n",
      "Epoch [1/3], Step [6300/12942], Loss: 2.2061, Perplexity: 9.08074\n",
      "Epoch [1/3], Step [6400/12942], Loss: 3.0754, Perplexity: 21.6576\n",
      "Epoch [1/3], Step [6500/12942], Loss: 2.5588, Perplexity: 12.9207\n",
      "Epoch [1/3], Step [6600/12942], Loss: 2.0721, Perplexity: 7.94125\n",
      "Epoch [1/3], Step [6700/12942], Loss: 2.0607, Perplexity: 7.85151\n",
      "Epoch [1/3], Step [6800/12942], Loss: 3.0214, Perplexity: 20.5207\n",
      "Epoch [1/3], Step [6900/12942], Loss: 2.3361, Perplexity: 10.3406\n",
      "Epoch [1/3], Step [7000/12942], Loss: 2.3389, Perplexity: 10.3701\n",
      "Epoch [1/3], Step [7100/12942], Loss: 2.0702, Perplexity: 7.92671\n",
      "Epoch [1/3], Step [7200/12942], Loss: 2.1627, Perplexity: 8.69450\n",
      "Epoch [1/3], Step [7300/12942], Loss: 2.2151, Perplexity: 9.16218\n",
      "Epoch [1/3], Step [7400/12942], Loss: 2.2088, Perplexity: 9.10516\n",
      "Epoch [1/3], Step [7500/12942], Loss: 2.2680, Perplexity: 9.66019\n",
      "Epoch [1/3], Step [7600/12942], Loss: 2.3566, Perplexity: 10.5550\n",
      "Epoch [1/3], Step [7700/12942], Loss: 2.2482, Perplexity: 9.47109\n",
      "Epoch [1/3], Step [7800/12942], Loss: 2.2845, Perplexity: 9.82095\n",
      "Epoch [1/3], Step [7900/12942], Loss: 2.2316, Perplexity: 9.31494\n",
      "Epoch [1/3], Step [8000/12942], Loss: 2.5652, Perplexity: 13.0035\n",
      "Epoch [1/3], Step [8100/12942], Loss: 2.2383, Perplexity: 9.37704\n",
      "Epoch [1/3], Step [8200/12942], Loss: 2.2295, Perplexity: 9.29550\n",
      "Epoch [1/3], Step [8300/12942], Loss: 2.2044, Perplexity: 9.06526\n",
      "Epoch [1/3], Step [8400/12942], Loss: 2.5437, Perplexity: 12.7262\n",
      "Epoch [1/3], Step [8500/12942], Loss: 2.1498, Perplexity: 8.58347\n",
      "Epoch [1/3], Step [8600/12942], Loss: 2.3441, Perplexity: 10.4235\n",
      "Epoch [1/3], Step [8700/12942], Loss: 2.0949, Perplexity: 8.12497\n",
      "Epoch [1/3], Step [8800/12942], Loss: 1.8330, Perplexity: 6.25242\n",
      "Epoch [1/3], Step [8900/12942], Loss: 2.0949, Perplexity: 8.124414\n",
      "Epoch [1/3], Step [9000/12942], Loss: 2.0763, Perplexity: 7.97468\n",
      "Epoch [1/3], Step [9100/12942], Loss: 2.6592, Perplexity: 14.2850\n",
      "Epoch [1/3], Step [9200/12942], Loss: 1.9542, Perplexity: 7.05814\n",
      "Epoch [1/3], Step [9300/12942], Loss: 2.0474, Perplexity: 7.74747\n",
      "Epoch [1/3], Step [9400/12942], Loss: 2.1621, Perplexity: 8.68973\n",
      "Epoch [1/3], Step [9500/12942], Loss: 2.9601, Perplexity: 19.3008\n",
      "Epoch [1/3], Step [9600/12942], Loss: 2.0546, Perplexity: 7.80396\n",
      "Epoch [1/3], Step [9700/12942], Loss: 2.4209, Perplexity: 11.2564\n",
      "Epoch [1/3], Step [9800/12942], Loss: 2.1192, Perplexity: 8.32410\n",
      "Epoch [1/3], Step [9900/12942], Loss: 1.7684, Perplexity: 5.86135\n",
      "Epoch [1/3], Step [10000/12942], Loss: 3.1623, Perplexity: 23.6253\n",
      "Epoch [1/3], Step [10100/12942], Loss: 2.2073, Perplexity: 9.09157\n",
      "Epoch [1/3], Step [10200/12942], Loss: 2.1870, Perplexity: 8.90864\n",
      "Epoch [1/3], Step [10300/12942], Loss: 2.2300, Perplexity: 9.29977\n",
      "Epoch [1/3], Step [10400/12942], Loss: 2.4351, Perplexity: 11.4169\n",
      "Epoch [1/3], Step [10500/12942], Loss: 1.9499, Perplexity: 7.02815\n",
      "Epoch [1/3], Step [10600/12942], Loss: 2.4747, Perplexity: 11.8784\n",
      "Epoch [1/3], Step [10700/12942], Loss: 2.2455, Perplexity: 9.44548\n",
      "Epoch [1/3], Step [10800/12942], Loss: 2.2295, Perplexity: 9.29553\n",
      "Epoch [1/3], Step [10900/12942], Loss: 2.1944, Perplexity: 8.97461\n",
      "Epoch [1/3], Step [11000/12942], Loss: 2.0945, Perplexity: 8.12113\n",
      "Epoch [1/3], Step [11100/12942], Loss: 2.2963, Perplexity: 9.93719\n",
      "Epoch [1/3], Step [11200/12942], Loss: 2.2140, Perplexity: 9.15236\n",
      "Epoch [1/3], Step [11300/12942], Loss: 2.1193, Perplexity: 8.32551\n",
      "Epoch [1/3], Step [11400/12942], Loss: 2.2297, Perplexity: 9.29743\n",
      "Epoch [1/3], Step [11500/12942], Loss: 1.9895, Perplexity: 7.31217\n",
      "Epoch [1/3], Step [11600/12942], Loss: 1.9793, Perplexity: 7.23772\n",
      "Epoch [1/3], Step [11700/12942], Loss: 2.3054, Perplexity: 10.0280\n",
      "Epoch [1/3], Step [11800/12942], Loss: 2.0972, Perplexity: 8.14339\n",
      "Epoch [1/3], Step [11900/12942], Loss: 2.1305, Perplexity: 8.41899\n",
      "Epoch [1/3], Step [12000/12942], Loss: 2.0222, Perplexity: 7.55514\n",
      "Epoch [1/3], Step [12100/12942], Loss: 2.1870, Perplexity: 8.90892\n",
      "Epoch [1/3], Step [12200/12942], Loss: 2.0328, Perplexity: 7.63557\n",
      "Epoch [1/3], Step [12300/12942], Loss: 2.8925, Perplexity: 18.0384\n",
      "Epoch [1/3], Step [12400/12942], Loss: 1.8492, Perplexity: 6.35503\n",
      "Epoch [1/3], Step [12500/12942], Loss: 2.1912, Perplexity: 8.94607\n",
      "Epoch [1/3], Step [12600/12942], Loss: 2.1999, Perplexity: 9.02427\n",
      "Epoch [1/3], Step [12700/12942], Loss: 2.0044, Perplexity: 7.42170\n",
      "Epoch [1/3], Step [12800/12942], Loss: 1.6782, Perplexity: 5.35593\n",
      "Epoch [1/3], Step [12900/12942], Loss: 2.0238, Perplexity: 7.56729\n",
      "Epoch [2/3], Step [100/12942], Loss: 2.1757, Perplexity: 8.8087235\n",
      "Epoch [2/3], Step [200/12942], Loss: 2.3145, Perplexity: 10.1201\n",
      "Epoch [2/3], Step [300/12942], Loss: 2.7241, Perplexity: 15.2422\n",
      "Epoch [2/3], Step [400/12942], Loss: 2.3331, Perplexity: 10.3097\n",
      "Epoch [2/3], Step [500/12942], Loss: 2.4415, Perplexity: 11.4904\n",
      "Epoch [2/3], Step [600/12942], Loss: 2.2213, Perplexity: 9.21964\n",
      "Epoch [2/3], Step [700/12942], Loss: 2.6140, Perplexity: 13.6539\n",
      "Epoch [2/3], Step [800/12942], Loss: 2.0990, Perplexity: 8.15804\n",
      "Epoch [2/3], Step [900/12942], Loss: 2.0278, Perplexity: 7.59753\n",
      "Epoch [2/3], Step [1000/12942], Loss: 1.7999, Perplexity: 6.0493\n",
      "Epoch [2/3], Step [1100/12942], Loss: 2.4676, Perplexity: 11.7946\n",
      "Epoch [2/3], Step [1200/12942], Loss: 2.1013, Perplexity: 8.17683\n",
      "Epoch [2/3], Step [1300/12942], Loss: 2.1267, Perplexity: 8.38744\n",
      "Epoch [2/3], Step [1400/12942], Loss: 2.1558, Perplexity: 8.63481\n",
      "Epoch [2/3], Step [1500/12942], Loss: 2.1874, Perplexity: 8.91232\n",
      "Epoch [2/3], Step [1600/12942], Loss: 2.0969, Perplexity: 8.14111\n",
      "Epoch [2/3], Step [1700/12942], Loss: 2.1329, Perplexity: 8.43917\n",
      "Epoch [2/3], Step [1800/12942], Loss: 2.4046, Perplexity: 11.0745\n",
      "Epoch [2/3], Step [1900/12942], Loss: 2.1298, Perplexity: 8.41306\n",
      "Epoch [2/3], Step [2000/12942], Loss: 2.2845, Perplexity: 9.82131\n",
      "Epoch [2/3], Step [2100/12942], Loss: 2.2351, Perplexity: 9.34750\n",
      "Epoch [2/3], Step [2200/12942], Loss: 2.1468, Perplexity: 8.55747\n",
      "Epoch [2/3], Step [2300/12942], Loss: 2.2135, Perplexity: 9.14720\n",
      "Epoch [2/3], Step [2400/12942], Loss: 2.0977, Perplexity: 8.14780\n",
      "Epoch [2/3], Step [2500/12942], Loss: 2.2257, Perplexity: 9.26007\n",
      "Epoch [2/3], Step [2600/12942], Loss: 2.3459, Perplexity: 10.4428\n",
      "Epoch [2/3], Step [2700/12942], Loss: 2.0712, Perplexity: 7.93403\n",
      "Epoch [2/3], Step [2800/12942], Loss: 2.1863, Perplexity: 8.90232\n",
      "Epoch [2/3], Step [2900/12942], Loss: 2.3006, Perplexity: 9.98010\n",
      "Epoch [2/3], Step [3000/12942], Loss: 2.1227, Perplexity: 8.35344\n",
      "Epoch [2/3], Step [3100/12942], Loss: 2.2063, Perplexity: 9.08223\n",
      "Epoch [2/3], Step [3200/12942], Loss: 2.2003, Perplexity: 9.02807\n",
      "Epoch [2/3], Step [3300/12942], Loss: 2.5880, Perplexity: 13.3028\n",
      "Epoch [2/3], Step [3400/12942], Loss: 2.0978, Perplexity: 8.14792\n",
      "Epoch [2/3], Step [3500/12942], Loss: 2.1325, Perplexity: 8.43608\n",
      "Epoch [2/3], Step [3600/12942], Loss: 1.9837, Perplexity: 7.26968\n",
      "Epoch [2/3], Step [3700/12942], Loss: 1.9610, Perplexity: 7.10651\n",
      "Epoch [2/3], Step [3800/12942], Loss: 2.0697, Perplexity: 7.92249\n",
      "Epoch [2/3], Step [3900/12942], Loss: 2.1351, Perplexity: 8.45808\n",
      "Epoch [2/3], Step [4000/12942], Loss: 2.0920, Perplexity: 8.10099\n",
      "Epoch [2/3], Step [4100/12942], Loss: 1.9777, Perplexity: 7.22640\n",
      "Epoch [2/3], Step [4200/12942], Loss: 2.1566, Perplexity: 8.64196\n",
      "Epoch [2/3], Step [4300/12942], Loss: 2.0946, Perplexity: 8.12192\n",
      "Epoch [2/3], Step [4400/12942], Loss: 1.8850, Perplexity: 6.58665\n",
      "Epoch [2/3], Step [4500/12942], Loss: 1.9242, Perplexity: 6.84966\n",
      "Epoch [2/3], Step [4600/12942], Loss: 2.0372, Perplexity: 7.66954\n",
      "Epoch [2/3], Step [4700/12942], Loss: 1.9427, Perplexity: 6.97741\n",
      "Epoch [2/3], Step [4800/12942], Loss: 2.3016, Perplexity: 9.99004\n",
      "Epoch [2/3], Step [4900/12942], Loss: 2.0086, Perplexity: 7.45273\n",
      "Epoch [2/3], Step [5000/12942], Loss: 2.1198, Perplexity: 8.32962\n",
      "Epoch [2/3], Step [5100/12942], Loss: 2.1630, Perplexity: 8.69695\n",
      "Epoch [2/3], Step [5200/12942], Loss: 2.0813, Perplexity: 8.01529\n",
      "Epoch [2/3], Step [5300/12942], Loss: 1.8743, Perplexity: 6.51602\n",
      "Epoch [2/3], Step [5400/12942], Loss: 2.0193, Perplexity: 7.53273\n",
      "Epoch [2/3], Step [5500/12942], Loss: 2.1930, Perplexity: 8.96244\n",
      "Epoch [2/3], Step [5600/12942], Loss: 1.8878, Perplexity: 6.60503\n",
      "Epoch [2/3], Step [5700/12942], Loss: 2.0325, Perplexity: 7.63288\n",
      "Epoch [2/3], Step [5800/12942], Loss: 2.0150, Perplexity: 7.50078\n",
      "Epoch [2/3], Step [5900/12942], Loss: 2.1177, Perplexity: 8.31183\n",
      "Epoch [2/3], Step [6000/12942], Loss: 1.8093, Perplexity: 6.10647\n",
      "Epoch [2/3], Step [6100/12942], Loss: 2.2021, Perplexity: 9.04434\n",
      "Epoch [2/3], Step [6200/12942], Loss: 2.3073, Perplexity: 10.0476\n",
      "Epoch [2/3], Step [6300/12942], Loss: 2.0994, Perplexity: 8.16147\n",
      "Epoch [2/3], Step [6400/12942], Loss: 2.2318, Perplexity: 9.31708\n",
      "Epoch [2/3], Step [6500/12942], Loss: 1.9569, Perplexity: 7.07733\n",
      "Epoch [2/3], Step [6600/12942], Loss: 2.2344, Perplexity: 9.34101\n",
      "Epoch [2/3], Step [6700/12942], Loss: 2.0218, Perplexity: 7.55192\n",
      "Epoch [2/3], Step [6800/12942], Loss: 2.1249, Perplexity: 8.37199\n",
      "Epoch [2/3], Step [6900/12942], Loss: 2.2984, Perplexity: 9.95850\n",
      "Epoch [2/3], Step [7000/12942], Loss: 2.1772, Perplexity: 8.82182\n",
      "Epoch [2/3], Step [7100/12942], Loss: 1.8708, Perplexity: 6.49337\n",
      "Epoch [2/3], Step [7200/12942], Loss: 2.0154, Perplexity: 7.50341\n",
      "Epoch [2/3], Step [7300/12942], Loss: 1.9843, Perplexity: 7.27384\n",
      "Epoch [2/3], Step [7400/12942], Loss: 2.0124, Perplexity: 7.48164\n",
      "Epoch [2/3], Step [7500/12942], Loss: 2.0344, Perplexity: 7.64744\n",
      "Epoch [2/3], Step [7600/12942], Loss: 2.1740, Perplexity: 8.79346\n",
      "Epoch [2/3], Step [7700/12942], Loss: 2.0765, Perplexity: 7.97616\n",
      "Epoch [2/3], Step [7800/12942], Loss: 1.9634, Perplexity: 7.12337\n",
      "Epoch [2/3], Step [7900/12942], Loss: 1.9583, Perplexity: 7.08708\n",
      "Epoch [2/3], Step [8000/12942], Loss: 2.1927, Perplexity: 8.95957\n",
      "Epoch [2/3], Step [8100/12942], Loss: 2.0797, Perplexity: 8.00236\n",
      "Epoch [2/3], Step [8200/12942], Loss: 2.4280, Perplexity: 11.3361\n",
      "Epoch [2/3], Step [8300/12942], Loss: 2.0655, Perplexity: 7.88956\n",
      "Epoch [2/3], Step [8400/12942], Loss: 2.4124, Perplexity: 11.1609\n",
      "Epoch [2/3], Step [8500/12942], Loss: 2.7683, Perplexity: 15.9309\n",
      "Epoch [2/3], Step [8600/12942], Loss: 2.0867, Perplexity: 8.05811\n",
      "Epoch [2/3], Step [8700/12942], Loss: 1.8899, Perplexity: 6.61855\n",
      "Epoch [2/3], Step [8800/12942], Loss: 1.9441, Perplexity: 6.98717\n",
      "Epoch [2/3], Step [8900/12942], Loss: 1.9816, Perplexity: 7.25464\n",
      "Epoch [2/3], Step [9000/12942], Loss: 2.2223, Perplexity: 9.22872\n",
      "Epoch [2/3], Step [9100/12942], Loss: 1.9275, Perplexity: 6.87246\n",
      "Epoch [2/3], Step [9200/12942], Loss: 2.0299, Perplexity: 7.61319\n",
      "Epoch [2/3], Step [9300/12942], Loss: 2.5985, Perplexity: 13.4429\n",
      "Epoch [2/3], Step [9400/12942], Loss: 2.0889, Perplexity: 8.07629\n",
      "Epoch [2/3], Step [9500/12942], Loss: 2.3060, Perplexity: 10.0345\n",
      "Epoch [2/3], Step [9600/12942], Loss: 1.8674, Perplexity: 6.47137\n",
      "Epoch [2/3], Step [9700/12942], Loss: 1.9836, Perplexity: 7.26919\n",
      "Epoch [2/3], Step [9800/12942], Loss: 2.2875, Perplexity: 9.85065\n",
      "Epoch [2/3], Step [9900/12942], Loss: 2.0365, Perplexity: 7.66396\n",
      "Epoch [2/3], Step [10000/12942], Loss: 2.0170, Perplexity: 7.5159\n",
      "Epoch [2/3], Step [10100/12942], Loss: 1.9456, Perplexity: 6.99771\n",
      "Epoch [2/3], Step [10200/12942], Loss: 2.1651, Perplexity: 8.71520\n",
      "Epoch [2/3], Step [10300/12942], Loss: 2.2324, Perplexity: 9.32206\n",
      "Epoch [2/3], Step [10400/12942], Loss: 2.0231, Perplexity: 7.56165\n",
      "Epoch [2/3], Step [10500/12942], Loss: 2.0547, Perplexity: 7.80481\n",
      "Epoch [2/3], Step [10600/12942], Loss: 1.9786, Perplexity: 7.23276\n",
      "Epoch [2/3], Step [10700/12942], Loss: 1.8680, Perplexity: 6.47534\n",
      "Epoch [2/3], Step [10800/12942], Loss: 1.9246, Perplexity: 6.85243\n",
      "Epoch [2/3], Step [10900/12942], Loss: 2.0119, Perplexity: 7.47752\n",
      "Epoch [2/3], Step [11000/12942], Loss: 1.9119, Perplexity: 6.76618\n",
      "Epoch [2/3], Step [11100/12942], Loss: 1.9005, Perplexity: 6.68911\n",
      "Epoch [2/3], Step [11200/12942], Loss: 1.9492, Perplexity: 7.02302\n",
      "Epoch [2/3], Step [11300/12942], Loss: 1.9106, Perplexity: 6.75718\n",
      "Epoch [2/3], Step [11400/12942], Loss: 2.0270, Perplexity: 7.59111\n",
      "Epoch [2/3], Step [11500/12942], Loss: 1.9861, Perplexity: 7.28682\n",
      "Epoch [2/3], Step [11600/12942], Loss: 1.7981, Perplexity: 6.03835\n",
      "Epoch [2/3], Step [11700/12942], Loss: 2.0632, Perplexity: 7.87102\n",
      "Epoch [2/3], Step [11800/12942], Loss: 1.8126, Perplexity: 6.12627\n",
      "Epoch [2/3], Step [11900/12942], Loss: 2.2594, Perplexity: 9.57778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Step [12000/12942], Loss: 2.1037, Perplexity: 8.19646\n",
      "Epoch [2/3], Step [12100/12942], Loss: 1.7800, Perplexity: 5.92965\n",
      "Epoch [2/3], Step [12200/12942], Loss: 2.1239, Perplexity: 8.36415\n",
      "Epoch [2/3], Step [12300/12942], Loss: 2.2884, Perplexity: 9.85936\n",
      "Epoch [2/3], Step [12400/12942], Loss: 1.8997, Perplexity: 6.68406\n",
      "Epoch [2/3], Step [12500/12942], Loss: 1.8047, Perplexity: 6.07803\n",
      "Epoch [2/3], Step [12600/12942], Loss: 1.7106, Perplexity: 5.53239\n",
      "Epoch [2/3], Step [12700/12942], Loss: 2.0088, Perplexity: 7.45467\n",
      "Epoch [2/3], Step [12800/12942], Loss: 1.8941, Perplexity: 6.64686\n",
      "Epoch [2/3], Step [12900/12942], Loss: 2.6583, Perplexity: 14.2715\n",
      "Epoch [3/3], Step [100/12942], Loss: 2.0701, Perplexity: 7.9259272\n",
      "Epoch [3/3], Step [200/12942], Loss: 2.0860, Perplexity: 8.05308\n",
      "Epoch [3/3], Step [300/12942], Loss: 2.6907, Perplexity: 14.7413\n",
      "Epoch [3/3], Step [400/12942], Loss: 2.0560, Perplexity: 7.81471\n",
      "Epoch [3/3], Step [500/12942], Loss: 2.0882, Perplexity: 8.07039\n",
      "Epoch [3/3], Step [600/12942], Loss: 1.9411, Perplexity: 6.96611\n",
      "Epoch [3/3], Step [700/12942], Loss: 1.8360, Perplexity: 6.27152\n",
      "Epoch [3/3], Step [800/12942], Loss: 1.9696, Perplexity: 7.16792\n",
      "Epoch [3/3], Step [900/12942], Loss: 2.5286, Perplexity: 12.5355\n",
      "Epoch [3/3], Step [1000/12942], Loss: 1.8794, Perplexity: 6.5494\n",
      "Epoch [3/3], Step [1100/12942], Loss: 2.0919, Perplexity: 8.10022\n",
      "Epoch [3/3], Step [1200/12942], Loss: 2.1857, Perplexity: 8.89680\n",
      "Epoch [3/3], Step [1300/12942], Loss: 1.9211, Perplexity: 6.82849\n",
      "Epoch [3/3], Step [1400/12942], Loss: 2.0894, Perplexity: 8.08022\n",
      "Epoch [3/3], Step [1500/12942], Loss: 1.7759, Perplexity: 5.90531\n",
      "Epoch [3/3], Step [1600/12942], Loss: 2.1347, Perplexity: 8.45436\n",
      "Epoch [3/3], Step [1700/12942], Loss: 2.1398, Perplexity: 8.49786\n",
      "Epoch [3/3], Step [1800/12942], Loss: 2.1472, Perplexity: 8.56081\n",
      "Epoch [3/3], Step [1900/12942], Loss: 1.8925, Perplexity: 6.63560\n",
      "Epoch [3/3], Step [2000/12942], Loss: 2.4944, Perplexity: 12.1147\n",
      "Epoch [3/3], Step [2100/12942], Loss: 2.1793, Perplexity: 8.84011\n",
      "Epoch [3/3], Step [2200/12942], Loss: 1.9988, Perplexity: 7.38066\n",
      "Epoch [3/3], Step [2300/12942], Loss: 2.0943, Perplexity: 8.119790\n",
      "Epoch [3/3], Step [2400/12942], Loss: 1.9996, Perplexity: 7.38634\n",
      "Epoch [3/3], Step [2500/12942], Loss: 1.6984, Perplexity: 5.46503\n",
      "Epoch [3/3], Step [2600/12942], Loss: 2.1853, Perplexity: 8.89332\n",
      "Epoch [3/3], Step [2700/12942], Loss: 1.8355, Perplexity: 6.26832\n",
      "Epoch [3/3], Step [2800/12942], Loss: 1.7385, Perplexity: 5.68905\n",
      "Epoch [3/3], Step [2900/12942], Loss: 2.1072, Perplexity: 8.22514\n",
      "Epoch [3/3], Step [3000/12942], Loss: 1.9363, Perplexity: 6.93339\n",
      "Epoch [3/3], Step [3100/12942], Loss: 1.9682, Perplexity: 7.15802\n",
      "Epoch [3/3], Step [3200/12942], Loss: 2.2779, Perplexity: 9.75602\n",
      "Epoch [3/3], Step [3300/12942], Loss: 2.0210, Perplexity: 7.54628\n",
      "Epoch [3/3], Step [3400/12942], Loss: 1.8483, Perplexity: 6.34884\n",
      "Epoch [3/3], Step [3500/12942], Loss: 2.1314, Perplexity: 8.42709\n",
      "Epoch [3/3], Step [3600/12942], Loss: 2.1807, Perplexity: 8.85249\n",
      "Epoch [3/3], Step [3700/12942], Loss: 1.8299, Perplexity: 6.23338\n",
      "Epoch [3/3], Step [3800/12942], Loss: 1.8967, Perplexity: 6.66385\n",
      "Epoch [3/3], Step [3900/12942], Loss: 2.1030, Perplexity: 8.19087\n",
      "Epoch [3/3], Step [4000/12942], Loss: 2.0525, Perplexity: 7.78750\n",
      "Epoch [3/3], Step [4100/12942], Loss: 2.0323, Perplexity: 7.63171\n",
      "Epoch [3/3], Step [4200/12942], Loss: 1.9014, Perplexity: 6.69550\n",
      "Epoch [3/3], Step [4300/12942], Loss: 2.0792, Perplexity: 7.99803\n",
      "Epoch [3/3], Step [4400/12942], Loss: 2.2154, Perplexity: 9.16477\n",
      "Epoch [3/3], Step [4500/12942], Loss: 1.8341, Perplexity: 6.25952\n",
      "Epoch [3/3], Step [4600/12942], Loss: 1.9044, Perplexity: 6.71524\n",
      "Epoch [3/3], Step [4700/12942], Loss: 1.9179, Perplexity: 6.80639\n",
      "Epoch [3/3], Step [4800/12942], Loss: 2.1483, Perplexity: 8.57046\n",
      "Epoch [3/3], Step [4900/12942], Loss: 2.0915, Perplexity: 8.09742\n",
      "Epoch [3/3], Step [5000/12942], Loss: 2.1726, Perplexity: 8.78070\n",
      "Epoch [3/3], Step [5100/12942], Loss: 2.2705, Perplexity: 9.68406\n",
      "Epoch [3/3], Step [5200/12942], Loss: 2.5450, Perplexity: 12.7426\n",
      "Epoch [3/3], Step [5300/12942], Loss: 2.0789, Perplexity: 7.99537\n",
      "Epoch [3/3], Step [5400/12942], Loss: 1.8147, Perplexity: 6.13947\n",
      "Epoch [3/3], Step [5500/12942], Loss: 1.7389, Perplexity: 5.69120\n",
      "Epoch [3/3], Step [5600/12942], Loss: 1.9718, Perplexity: 7.18331\n",
      "Epoch [3/3], Step [5700/12942], Loss: 1.8551, Perplexity: 6.39223\n",
      "Epoch [3/3], Step [5800/12942], Loss: 2.0095, Perplexity: 7.45949\n",
      "Epoch [3/3], Step [5900/12942], Loss: 2.9219, Perplexity: 18.5760\n",
      "Epoch [3/3], Step [6000/12942], Loss: 1.9843, Perplexity: 7.27361\n",
      "Epoch [3/3], Step [6100/12942], Loss: 2.1643, Perplexity: 8.70858\n",
      "Epoch [3/3], Step [6200/12942], Loss: 2.0240, Perplexity: 7.56839\n",
      "Epoch [3/3], Step [6300/12942], Loss: 2.0523, Perplexity: 7.78621\n",
      "Epoch [3/3], Step [6400/12942], Loss: 1.7677, Perplexity: 5.85716\n",
      "Epoch [3/3], Step [6500/12942], Loss: 1.6502, Perplexity: 5.20820\n",
      "Epoch [3/3], Step [6600/12942], Loss: 1.7700, Perplexity: 5.87118\n",
      "Epoch [3/3], Step [6700/12942], Loss: 1.9567, Perplexity: 7.07597\n",
      "Epoch [3/3], Step [6800/12942], Loss: 1.9989, Perplexity: 7.38111\n",
      "Epoch [3/3], Step [6900/12942], Loss: 1.9002, Perplexity: 6.68729\n",
      "Epoch [3/3], Step [7000/12942], Loss: 2.0826, Perplexity: 8.02550\n",
      "Epoch [3/3], Step [7100/12942], Loss: 2.0211, Perplexity: 7.54686\n",
      "Epoch [3/3], Step [7200/12942], Loss: 2.2858, Perplexity: 9.83319\n",
      "Epoch [3/3], Step [7300/12942], Loss: 1.8765, Perplexity: 6.53091\n",
      "Epoch [3/3], Step [7400/12942], Loss: 1.9508, Perplexity: 7.03457\n",
      "Epoch [3/3], Step [7500/12942], Loss: 1.6612, Perplexity: 5.26540\n",
      "Epoch [3/3], Step [7600/12942], Loss: 1.9103, Perplexity: 6.75535\n",
      "Epoch [3/3], Step [7700/12942], Loss: 2.4990, Perplexity: 12.1701\n",
      "Epoch [3/3], Step [7800/12942], Loss: 2.3047, Perplexity: 10.0208\n",
      "Epoch [3/3], Step [7900/12942], Loss: 1.7739, Perplexity: 5.89377\n",
      "Epoch [3/3], Step [8000/12942], Loss: 2.1874, Perplexity: 8.91182\n",
      "Epoch [3/3], Step [8100/12942], Loss: 2.0708, Perplexity: 7.93158\n",
      "Epoch [3/3], Step [8200/12942], Loss: 1.8922, Perplexity: 6.63382\n",
      "Epoch [3/3], Step [8300/12942], Loss: 1.9428, Perplexity: 6.97851\n",
      "Epoch [3/3], Step [8400/12942], Loss: 2.0965, Perplexity: 8.13735\n",
      "Epoch [3/3], Step [8500/12942], Loss: 1.9224, Perplexity: 6.83767\n",
      "Epoch [3/3], Step [8600/12942], Loss: 2.2327, Perplexity: 9.32505\n",
      "Epoch [3/3], Step [8700/12942], Loss: 2.3331, Perplexity: 10.3095\n",
      "Epoch [3/3], Step [8800/12942], Loss: 1.9863, Perplexity: 7.28854\n",
      "Epoch [3/3], Step [8900/12942], Loss: 2.2318, Perplexity: 9.31649\n",
      "Epoch [3/3], Step [9000/12942], Loss: 2.1016, Perplexity: 8.17921\n",
      "Epoch [3/3], Step [9100/12942], Loss: 1.8823, Perplexity: 6.56832\n",
      "Epoch [3/3], Step [9200/12942], Loss: 2.1569, Perplexity: 8.644679\n",
      "Epoch [3/3], Step [9300/12942], Loss: 2.1123, Perplexity: 8.26766\n",
      "Epoch [3/3], Step [9400/12942], Loss: 1.8275, Perplexity: 6.21858\n",
      "Epoch [3/3], Step [9500/12942], Loss: 2.1520, Perplexity: 8.60174\n",
      "Epoch [3/3], Step [9600/12942], Loss: 2.0993, Perplexity: 8.16044\n",
      "Epoch [3/3], Step [9700/12942], Loss: 1.8868, Perplexity: 6.59810\n",
      "Epoch [3/3], Step [9800/12942], Loss: 1.7661, Perplexity: 5.84810\n",
      "Epoch [3/3], Step [9900/12942], Loss: 1.7944, Perplexity: 6.01611\n",
      "Epoch [3/3], Step [10000/12942], Loss: 1.8629, Perplexity: 6.4423\n",
      "Epoch [3/3], Step [10100/12942], Loss: 1.7230, Perplexity: 5.60143\n",
      "Epoch [3/3], Step [10200/12942], Loss: 2.1179, Perplexity: 8.31368\n",
      "Epoch [3/3], Step [10300/12942], Loss: 2.1193, Perplexity: 8.32523\n",
      "Epoch [3/3], Step [10400/12942], Loss: 2.2190, Perplexity: 9.19807\n",
      "Epoch [3/3], Step [10500/12942], Loss: 1.9086, Perplexity: 6.74404\n",
      "Epoch [3/3], Step [10600/12942], Loss: 1.7239, Perplexity: 5.60654\n",
      "Epoch [3/3], Step [10700/12942], Loss: 2.0576, Perplexity: 7.82737\n",
      "Epoch [3/3], Step [10800/12942], Loss: 2.1464, Perplexity: 8.55423\n",
      "Epoch [3/3], Step [10900/12942], Loss: 2.2581, Perplexity: 9.56536\n",
      "Epoch [3/3], Step [10950/12942], Loss: 2.3865, Perplexity: 10.8749"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "old_time = time.time()\n",
    "response = requests.request(\"GET\", \n",
    "                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        if time.time() - old_time > 60:\n",
    "            old_time = time.time()\n",
    "            requests.request(\"POST\", \n",
    "                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "                             headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: (Optional) Validate your Model\n",
    "\n",
    "To assess potential overfitting, one approach is to assess performance on a validation set.  If you decide to do this **optional** task, you are required to first complete all of the steps in the next notebook in the sequence (**3_Inference.ipynb**); as part of that notebook, you will write and test code (specifically, the `sample` method in the `DecoderRNN` class) that uses your RNN decoder to generate captions.  That code will prove incredibly useful here. \n",
    "\n",
    "If you decide to validate your model, please do not edit the data loader in **data_loader.py**.  Instead, create a new file named **data_loader_val.py** containing the code for obtaining the data loader for the validation data.  You can access:\n",
    "- the validation images at filepath `'/opt/cocoapi/images/train2014/'`, and\n",
    "- the validation image caption annotation file at filepath `'/opt/cocoapi/annotations/captions_val2014.json'`.\n",
    "\n",
    "The suggested approach to validating your model involves creating a json file such as [this one](https://github.com/cocodataset/cocoapi/blob/master/results/captions_val2014_fakecap_results.json) containing your model's predicted captions for the validation images.  Then, you can write your own script or use one that you [find online](https://github.com/tylin/coco-caption) to calculate the BLEU score of your model.  You can read more about the BLEU score, along with other evaluation metrics (such as TEOR and Cider) in section 4.1 of [this paper](https://arxiv.org/pdf/1411.4555.pdf).  For more information about how to use the annotation file, check out the [website](http://cocodataset.org/#download) for the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) TODO: Validate your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
